{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import itertools\n",
    "import nltk\n",
    "import numpy as np\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/iliapl/Documents/CoronaVirusProject/repo/corona_healthcare_workers/manual_labeling/datasets/Dataset_ready_for_classification/\"\n",
    "output_path = \"C:/Users/iliapl/Documents/CoronaVirusProject/repo/corona_healthcare_workers/manual_labeling/datasets/Classification_results/\"\n",
    "num_rounds_finished = 20\n",
    "healthcare_workers_df = pd.read_csv(path + \"classified_hcp_manual_labeling_{0}_rounds_with_features.csv\".format(num_rounds_finished))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals_only = True\n",
    "INDIVIDUAL_CONFIDENCE_PERCENT = 90\n",
    "\n",
    "confidence_percentile = (100 - INDIVIDUAL_CONFIDENCE_PERCENT) / 100\n",
    "\n",
    "if individuals_only:\n",
    "        \n",
    "    # labeled individuals\n",
    "    labeled_individuals_df = healthcare_workers_df[healthcare_workers_df['Account_Type (Individual/Organization/Other)'] == 'Individual'].reset_index(drop=True)\n",
    "    \n",
    "    # unlabeled individuals\n",
    "    unlabeled_individuals_df = pd.read_csv(output_path + 'unlabeled_predictions_Account_Type_using_author_full_name_and_description_and_SVM_classifier_balanced.csv')\n",
    "    unlabeled_individuals_df = unlabeled_individuals_df[unlabeled_individuals_df['confidence_to_class_1'] <= confidence_percentile]\n",
    "    healthcare_workers_df = pd.concat([labeled_individuals_df,\n",
    "                                      healthcare_workers_df[healthcare_workers_df['username'].isin(unlabeled_individuals_df['author_screen_name'])]])\n",
    "    healthcare_workers_df = healthcare_workers_df.reset_index(drop=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set target field and binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_field indicates type of classifier (target variable)\n",
    "\n",
    "#target_field = \"Account_Type (Individual/Organization/Other)\"\n",
    "#mapping_dict = {\n",
    "#    \"Individual\": 0,\n",
    "#    \"Organization\": 1\n",
    "#}\n",
    "\n",
    "target_field = \"Occupation_Type (HCP/Not HCP)\"\n",
    "mapping_dict = {\n",
    "    \"Hcp\": 0,\n",
    "    \"Not hcp\": 1\n",
    "}\n",
    "\n",
    "\n",
    "inverse_mapping_dict = {v: k for k, v in mapping_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert category to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Category to numbers\n",
    "healthcare_workers_df['author_type_numeric'] = healthcare_workers_df[target_field].map(mapping_dict)\n",
    "healthcare_workers_df['author_full_name_and_description'] = healthcare_workers_df['author_full_name'].str.cat(healthcare_workers_df['description'],sep=\" \")\n",
    "\n",
    "healthcare_workers_df = healthcare_workers_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "# labeled_df = healthcare_workers_df[(healthcare_workers_df[\"author_sub_type\"] == 'PERSON') | \n",
    "#                                    (healthcare_workers_df[\"author_sub_type\"] == 'ORANIZATION')]\n",
    "\n",
    "# unlabeled_df = healthcare_workers_df[(healthcare_workers_df[\"author_sub_type\"] != 'PERSON') & \n",
    "#                                    (healthcare_workers_df[\"author_sub_type\"] != 'ORANIZATION')]\n",
    "\n",
    "# y = healthcare_workers_df['author_type_numeric']\n",
    "# y_labeled = y[labeled_indexes]\n",
    "# y_unlabeled = y[unlabeled_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = healthcare_workers_df[(healthcare_workers_df[\"author_type_numeric\"] == 0) | \n",
    "                              (healthcare_workers_df[\"author_type_numeric\"] == 1)]\n",
    "labeled_indexes = labeled_df.index\n",
    "unlabeled_df = healthcare_workers_df.loc[~healthcare_workers_df.index.isin(labeled_indexes)]\n",
    "unlabeled_indexes = unlabeled_df.index\n",
    "\n",
    "y = healthcare_workers_df['author_type_numeric']\n",
    "y_labeled = y[labeled_indexes]\n",
    "y_labeled = y_labeled.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_types, extraction types, classifiers, etc. create cartesian products of each configuration\n",
    "\n",
    "targeted_fields = ['description', 'author_full_name_and_description']\n",
    "#targeted_fields = ['description']\n",
    "#targeted_fields = ['author_full_name_and_description']\n",
    "#experiment_types = ['balanced']\n",
    "experiment_types = [\"balanced\"] # there is also inbalanced - if both are set then two separate experiments are run (cartesian products)\n",
    "#targeted_fields = ['author_full_name_and_description']\n",
    "is_remove_stopwords = [False]\n",
    "#feature_extraction_types = ['Doc2Vec']\n",
    "#feature_extraction_types = ['bag_of_words']\n",
    "feature_extraction_types = ['tf_idf']\n",
    "classifiers = ['SVM']\n",
    "#classifiers = ['SVM']\n",
    "#vector_sizes = [2, 3 , 5, 10, 20, 50, 100, 300]\n",
    "vector_sizes = [100]\n",
    "window_sizes = [2]\n",
    "#k_folds = [1, 10]\n",
    "k_folds = [10]\n",
    "#author_features = ['statuses_count', 'followers_count', 'favourites_count', 'friends_count', 'listed_count','verified']\n",
    "author_features = ['favourites_count', 'listed_count']\n",
    "normalize_features = ['statuses_count', 'followers_count', 'favourites_count', 'friends_count', 'listed_count']\n",
    "\n",
    "with_author_features = False\n",
    "with_normalized_features = False\n",
    "\n",
    "experiment_params = [targeted_fields, is_remove_stopwords, feature_extraction_types, classifiers, vector_sizes, \n",
    "                     window_sizes, k_folds, experiment_types]\n",
    "combinations = list(itertools.product(*experiment_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not with_author_features and with_normalized_features:\n",
    "    raise ValueError('Please set with_normalized_features to False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add normalized columns for author features if necessary\n",
    "\n",
    "if with_author_features:\n",
    "    healthcare_workers_df['friends_followers_ratio'] = healthcare_workers_df['friends_count'] / healthcare_workers_df['followers_count']\n",
    "    healthcare_workers_df['friends_followers_ratio'] = healthcare_workers_df['friends_followers_ratio'].replace(np.inf, np.nan)\n",
    "    healthcare_workers_df['friends_followers_ratio'] = healthcare_workers_df['friends_followers_ratio'].replace(np.nan, healthcare_workers_df['friends_followers_ratio'].max())\n",
    "    series = healthcare_workers_df['friends_followers_ratio']\n",
    "    healthcare_workers_df['friends_followers_ratio'] = (series - series.min()) / (series.max() - series.min())\n",
    "    \n",
    "    author_features.append('friends_followers_ratio')\n",
    "    \n",
    "    if with_normalized_features:\n",
    "        for column in normalize_features:\n",
    "            series = healthcare_workers_df[column]\n",
    "            healthcare_workers_df['{}_normalized'.format(column)] = (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "        author_features = ['{}{}'.format(feature, '_normalized' if feature in normalize_features else '') for feature in author_features]\n",
    "\n",
    "        print(author_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_idf_features(df, targeted_field):\n",
    "    df['selected_field'] = df[targeted_field].apply(str)\n",
    "    \n",
    "    corpus = df['selected_field'].to_list()\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation(clf, X, y, k_fold):\n",
    "    scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "    scores = cross_validate(clf, X, y, cv=k_fold,scoring=scoring, return_train_score=False)\n",
    "    print(scores)\n",
    "\n",
    "    avg_accuracy = scores['test_accuracy'].mean()\n",
    "    avg_f1 = scores['test_f1_macro'].mean()\n",
    "    avg_precision = scores['test_precision_macro'].mean()\n",
    "    avg_recall = scores['test_recall_macro'].mean()\n",
    "    \n",
    "    return avg_accuracy, avg_f1, avg_precision, avg_recall\n",
    "\n",
    "def make_leave_one_out(clf, X, y):\n",
    "    loo = LeaveOneOut()\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "            \n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "            \n",
    "        f1 = f1_score(y_test, predictions, average='weighted')\n",
    "        f1s.append(f1)\n",
    "            \n",
    "        precision = precision_score(y_test, predictions, average='weighted')\n",
    "        precisions.append(precision)\n",
    "            \n",
    "        recall = recall_score(y_test, predictions, average='weighted')\n",
    "        recalls.append(recall)\n",
    "            \n",
    "    accuracies_series = pd.Series(accuracies)\n",
    "    avg_accuracy = accuracies_series.mean()\n",
    "    \n",
    "    f1s_series = pd.Series(f1s)\n",
    "    avg_f1 = f1s_series.mean()\n",
    "    \n",
    "    precisions_series = pd.Series(precisions)\n",
    "    avg_precision = precisions_series.mean()\n",
    "    \n",
    "    recalls_series = pd.Series(recalls)\n",
    "    avg_recall = recalls_series.mean()\n",
    "    \n",
    "    return avg_accuracy, avg_f1, avg_precision, avg_recall          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "#for i in range(10):\n",
    "for i in range(1):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for combination in tqdm(combinations):\n",
    "        targeted_field = combination[0]\n",
    "        is_remove_stop_words = combination[1]\n",
    "        feature_extraction_type = combination[2]\n",
    "        selected_classifier = combination[3]\n",
    "        vector_size = combination[4]\n",
    "        window_size = combination[5]\n",
    "        k = combination[6]\n",
    "        experiment_type = combination[7]\n",
    "\n",
    "        print(\"targeted_field: {0}, is_remove_stop_words: {1}, feature_extraction_type: {2}, \\\n",
    "                selected_classifier: {3}, vector_size: {4}, window_size:{5}, \\\n",
    "                k:{6}, experiment_type: {7}\".format(targeted_field, is_remove_stop_words, selected_classifier, feature_extraction_type, \n",
    "                              vector_size, window_size, k, experiment_type))\n",
    "\n",
    "        if experiment_type == \"inbalanced\":\n",
    "            labeled_df = healthcare_workers_df[(healthcare_workers_df[\"author_type_numeric\"] == 0) | \n",
    "                                  (healthcare_workers_df[\"author_type_numeric\"] == 1)]\n",
    "            labeled_indexes = labeled_df.index\n",
    "\n",
    "            y = healthcare_workers_df['author_type_numeric']\n",
    "            y_labeled = y[labeled_indexes]\n",
    "            y_labeled = y_labeled.astype('int')\n",
    "\n",
    "            class_0_df = healthcare_workers_df[healthcare_workers_df['author_type_numeric'] == 0]\n",
    "            num_of_class_0 = class_0_df.shape[0]\n",
    "            print(num_of_class_0)\n",
    "\n",
    "            class_1_df = healthcare_workers_df[healthcare_workers_df['author_type_numeric'] == 1]\n",
    "            num_of_class_1 = class_1_df.shape[0]\n",
    "            print(num_of_class_1)\n",
    "\n",
    "        elif experiment_type == \"balanced\":\n",
    "\n",
    "            class_0_df = healthcare_workers_df[healthcare_workers_df['author_type_numeric'] == 0]\n",
    "            num_of_class_0 = class_0_df.shape[0]\n",
    "            print(num_of_class_0)\n",
    "\n",
    "            class_1_df = healthcare_workers_df[healthcare_workers_df['author_type_numeric'] == 1]\n",
    "            num_of_class_1 = class_1_df.shape[0]\n",
    "            print(num_of_class_1)\n",
    "\n",
    "            if num_of_class_0 != num_of_class_1:\n",
    "                min_num = min(num_of_class_0, num_of_class_1)\n",
    "                # for balanced process we want the same amount of instances for each class\n",
    "                class_0_df = class_0_df.sample(n=min_num)\n",
    "                class_1_df = class_1_df.sample(n=min_num)\n",
    "            \n",
    "            class_0_index = class_0_df.index\n",
    "            class_1_index = class_1_df.index\n",
    "\n",
    "            labeled_indexes = class_0_index.union(class_1_index)\n",
    "\n",
    "            y_labeled = y[labeled_indexes]\n",
    "            y_labeled = y_labeled.astype('int')\n",
    "\n",
    "            num_of_class_0 = class_0_index.size\n",
    "            print(num_of_class_0)\n",
    "            num_of_class_1 = class_1_index.size\n",
    "            print(num_of_class_1)\n",
    "\n",
    "\n",
    "        if feature_extraction_type == \"tf_idf\":\n",
    "            X = create_tf_idf_features(healthcare_workers_df, targeted_field)\n",
    "\n",
    "        elif feature_extraction_type == \"Doc2Vec\":\n",
    "            healthcare_workers_df = make_preprocessing(healthcare_workers_df, targeted_field)\n",
    "            healthcare_workers_df = handle_stop_words(healthcare_workers_df, is_remove_stop_words)\n",
    "            X, y = create_doc2vec_classifier_and_train_results(users_and_organizations_df, twitter_users_targeted_field_df, vector_size, window_size)\n",
    "\n",
    "        X_labeled = X[labeled_indexes]\n",
    "        if with_author_features:\n",
    "            #X_labeled = pd.concat([pd.DataFrame(X_labeled.toarray()), \n",
    "            #                       healthcare_workers_df[author_features][healthcare_workers_df.index.isin(labeled_indexes)].reset_index(drop=True)], axis=1)        \n",
    "            X_labeled = scipy.sparse.hstack([X_labeled, scipy.sparse.csr_matrix(healthcare_workers_df[author_features][healthcare_workers_df.index.isin(labeled_indexes)].values)])\n",
    "            print('Added author features')\n",
    "        #y_labeled = y[labeled_indexes]\n",
    "\n",
    "        if selected_classifier == 'SVM':\n",
    "            clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "        elif selected_classifier == 'RandomForest':\n",
    "            clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "        elif selected_classifier == 'NB':\n",
    "            clf = GaussianNB()\n",
    "            X_labeled = X_labeled.toarray()\n",
    "\n",
    "        if k != 1:\n",
    "            avg_accuracy, avg_f1, avg_precision, avg_recall = make_cross_validation(clf, X_labeled, y_labeled, k)\n",
    "            print('ACCURACY:', avg_accuracy)\n",
    "        else: # LEAVE ONE OUT\n",
    "            avg_accuracy, avg_f1, avg_precision, avg_recall = make_leave_one_out(clf, X_labeled, y_labeled)\n",
    "\n",
    "\n",
    "        result = (target_field, num_of_class_0, num_of_class_1, targeted_field, is_remove_stop_words, \n",
    "                  feature_extraction_type, vector_size, window_size, selected_classifier, k, \n",
    "                      avg_accuracy, avg_f1, avg_precision, avg_recall)\n",
    "        results.append(result)\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['target_class_field', '#Class_0', '#Class_1', 'Targeted_Field', 'Remove_Stopwords', \n",
    "                                                'Feature_Extraction_Type', 'Vector_Size', 'Window_Size', 'Classifier', \n",
    "                                                'K', 'Accuracy', 'F1', 'Precision', 'Recall'])\n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "    if not os.path.exists(output_path + 'Round_{0}'.format(num_rounds_finished)):\n",
    "        os.mkdir(output_path + 'Round_{0}'.format(num_rounds_finished))\n",
    "\n",
    "    # add target field and round number to file name\n",
    "    #results_df.to_csv(output_path + \"Round_{0}/classifications_round_{1}_target_{2}{3}{4}_{5}{6}.csv\".format(num_rounds_finished, \n",
    "    #                                                                                                num_rounds_finished,\n",
    "    #                                                                                      target_field[:target_field.index(' ')],\n",
    "    #                                                                                            '_individuals_only' if individuals_only else '',\n",
    "    #                                                                                      '_with_author_features' if with_author_features else '',\n",
    "    #                                                                                                   'normalized_' if with_normalized_features else '',\n",
    "    #                                                                                                   date_time), index=False)\n",
    "\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train best classifier and predict on unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targeted_field = \"author_full_name_and_description\"\n",
    "#targeted_field = \"description\"\n",
    "selected_classifier = \"SVM\"\n",
    "experiment_type = \"balanced\"\n",
    "\n",
    "if selected_classifier == 'SVM':\n",
    "    clf = svm.SVC(kernel='linear', C=1, random_state=0, probability=True)\n",
    "elif selected_classifier == 'RandomForest':\n",
    "    clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "    \n",
    "X = create_tf_idf_features(healthcare_workers_df, targeted_field)\n",
    "\n",
    "if experiment_type == \"balanced\":\n",
    "#     labeled_person_df = healthcare_workers_df[healthcare_workers_df[\"author_sub_type\"] == 'PERSON']\n",
    "#     balanced_person_df = labeled_person_df.sample(n=119)\n",
    "#     labeled_persons_index = balanced_person_df.index\n",
    "\n",
    "#     labeled_organizations_df = healthcare_workers_df[healthcare_workers_df[\"author_sub_type\"] == 'ORANIZATION']\n",
    "#     labeled_organizations_index = labeled_organizations_df.index\n",
    "\n",
    "#     labeled_indexes = labeled_persons_index.union(labeled_organizations_index)\n",
    "\n",
    "#     y_labeled = y[labeled_indexes]\n",
    "#     y_labeled = y_labeled.astype('int')\n",
    "        \n",
    "    class_0_df = healthcare_workers_df[healthcare_workers_df['author_type_numeric'] == 0]\n",
    "    num_of_class_0 = class_0_df.shape[0]\n",
    "    print(num_of_class_0)\n",
    "        \n",
    "    class_1_df = healthcare_workers_df[healthcare_workers_df['author_type_numeric'] == 1]\n",
    "    num_of_class_1 = class_1_df.shape[0]\n",
    "    print(num_of_class_1)\n",
    "        \n",
    "    if num_of_class_0 != num_of_class_1:\n",
    "        min_num = min(num_of_class_0, num_of_class_1)\n",
    "        class_0_df = class_0_df.sample(n=min_num)\n",
    "        class_0_index = class_0_df.index\n",
    "            \n",
    "        class_1_df = class_1_df.sample(n=min_num)\n",
    "        class_1_index = class_1_df.index\n",
    "    \n",
    "    labeled_indexes = class_0_index.union(class_1_index)\n",
    "    print(labeled_indexes.shape)\n",
    "        \n",
    "    y_labeled = y[labeled_indexes]\n",
    "    y_labeled = y_labeled.astype('int')\n",
    "        \n",
    "elif experiment_type == \"inbalanced\":\n",
    "    labeled_df = healthcare_workers_df[(healthcare_workers_df[\"author_type_numeric\"] == 0) | \n",
    "                              (healthcare_workers_df[\"author_type_numeric\"] == 1)]\n",
    "    labeled_indexes = labeled_df.index\n",
    "\n",
    "    y = healthcare_workers_df['author_type_numeric']\n",
    "    y_labeled = y[labeled_indexes]\n",
    "    y_labeled = y_labeled.astype('int')\n",
    "\n",
    "X_labeled = X[labeled_indexes]\n",
    "if with_author_features:\n",
    "    X_labeled = pd.concat([pd.DataFrame(X_labeled.toarray()), \n",
    "                           healthcare_workers_df[author_features][healthcare_workers_df.index.isin(labeled_indexes)].reset_index(drop=True)], axis=1)        \n",
    "    print('Added author features')\n",
    "\n",
    "clf.fit(X_labeled, y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabeled = X[unlabeled_indexes]\n",
    "if with_author_features:\n",
    "    X_unlabeled = pd.concat([pd.DataFrame(X_unlabeled.toarray()), \n",
    "                           healthcare_workers_df[author_features][healthcare_workers_df.index.isin(unlabeled_indexes)].reset_index(drop=True)], axis=1)        \n",
    "    print('Added author features')\n",
    "\n",
    "pred = clf.predict_proba(X_unlabeled)\n",
    "\n",
    "predict_pobabilities = pred[:, 1]\n",
    "\n",
    "df = pd.DataFrame(predict_pobabilities, columns=['predict_pob'])\n",
    "\n",
    "df['automatic_prediction'] = df['predict_pob'].apply(lambda x:1 if x>=0.5 else 0)\n",
    "predictions_series = df['automatic_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_screen_names = healthcare_workers_df['author_screen_name'][unlabeled_indexes]\n",
    "author_full_names = healthcare_workers_df['author_full_name'][unlabeled_indexes]\n",
    "descriptions = healthcare_workers_df['description'][unlabeled_indexes]\n",
    "author_full_name_and_descriptions = healthcare_workers_df['author_full_name_and_description'][unlabeled_indexes]\n",
    "author_osn_ids = healthcare_workers_df['author_osn_id'][unlabeled_indexes]\n",
    "\n",
    "\n",
    "unlabeled_predictions_df = pd.DataFrame(author_screen_names, columns=['author_screen_name'])\n",
    "\n",
    "unlabeled_predictions_df['author_full_name'] = author_full_names\n",
    "unlabeled_predictions_df['description'] = descriptions\n",
    "unlabeled_predictions_df['author_full_name_and_description'] = author_full_name_and_descriptions\n",
    "unlabeled_predictions_df['author_osn_id'] = author_osn_ids\n",
    "\n",
    "unlabeled_predictions_df = unlabeled_predictions_df.reset_index(drop=True)\n",
    "\n",
    "unlabeled_predictions_df['confidence_to_class_1'] = df['predict_pob']\n",
    "unlabeled_predictions_df['automatic_prediction'] = df['automatic_prediction']\n",
    "unlabeled_predictions_df['str_automatic_prediction'] = df['automatic_prediction'].map(inverse_mapping_dict)\n",
    "\n",
    "\n",
    "#short_unlabeled_predictions_df = unlabeled_predictions_df[((unlabeled_predictions_df['confidence_to_class_1'] >= 0.4) & \n",
    "#                                                             (unlabeled_predictions_df['confidence_to_class_1'] < 0.6))]\n",
    "\n",
    "\n",
    "#unlabeled_predictions_df = unlabeled_predictions_df.sort_values(by=['confidence_to_class_1'])\n",
    "\n",
    "\n",
    "unlabeled_predictions_df.to_csv(output_path + \"unlabeled_predictions_{0}{1}_using_{2}_and_{3}_classifier_{4}.csv\".format(target_field[:target_field.index(' ')],\n",
    "                                                                                                                                  '_individuals_only' if individuals_only else '',\n",
    "                                                                                                                            targeted_field, \n",
    "                                                                                                           selected_classifier,\n",
    "                                                                                                           experiment_type), \n",
    "                                index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance on users of iterations 1, 2, 3 separately, train on all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = pd.Series()\n",
    "\n",
    "validation_iteration = 1\n",
    "for i in range(1, num_rounds_finished + 1):\n",
    "    if i != validation_iteration:\n",
    "        train_users = train_users.append(pd.read_csv('C:/Users/iliapl/Documents/CoronaVirusProject/repo/corona_healthcare_workers/manual_labeling/datasets/Round_{}/agreed_round_{}_after_summit.csv'.format(i, i))['username'])\n",
    "\n",
    "train_users_df = healthcare_workers_df[healthcare_workers_df['username'].isin(train_users)]\n",
    "\n",
    "validation_users = pd.read_csv('C:/Users/iliapl/Documents/CoronaVirusProject/repo/corona_healthcare_workers/manual_labeling/datasets/Round_{}/agreed_round_{}_after_summit.csv'.format(validation_iteration, validation_iteration))['username']\n",
    "validation_users_df = healthcare_workers_df[healthcare_workers_df['username'].isin(validation_users)]\n",
    "validation_users_df = validation_users_df[validation_users_df['Account_Type (Individual/Organization/Other)'] != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "targeted_field = 'author_full_name_and_description'\n",
    "is_remove_stop_words = False\n",
    "feature_extraction_type = 'tf-idf'\n",
    "selected_classifier = 'SVM'\n",
    "vector_size = 100\n",
    "window_size = 2\n",
    "\n",
    "class_0_df = train_users_df[train_users_df['author_type_numeric'] == 0]\n",
    "num_of_class_0 = class_0_df.shape[0]\n",
    "print(num_of_class_0)\n",
    "\n",
    "class_1_df = train_users_df[train_users_df['author_type_numeric'] == 1]\n",
    "num_of_class_1 = class_1_df.shape[0]\n",
    "print(num_of_class_1)\n",
    "\n",
    "if num_of_class_0 != num_of_class_1:\n",
    "    min_num = min(num_of_class_0, num_of_class_1)\n",
    "    # for balanced process we want the same amount of instances for each class\n",
    "    class_0_df = class_0_df.sample(n=min_num)\n",
    "    class_0_index = class_0_df.index\n",
    "\n",
    "    class_1_df = class_1_df.sample(n=min_num)\n",
    "    class_1_index = class_1_df.index\n",
    "\n",
    "labeled_indexes = class_0_index.union(class_1_index)\n",
    "\n",
    "y_labeled = y[labeled_indexes]\n",
    "y_labeled = y_labeled.astype('int')\n",
    "\n",
    "num_of_class_0 = class_0_index.size\n",
    "print(num_of_class_0)\n",
    "num_of_class_1 = class_1_index.size\n",
    "print(num_of_class_1)\n",
    "\n",
    "\n",
    "X = create_tf_idf_features(healthcare_workers_df, targeted_field)\n",
    "\n",
    "X_labeled = X[labeled_indexes]\n",
    "if with_author_features:\n",
    "    X_labeled = pd.concat([pd.DataFrame(X_labeled.toarray()), \n",
    "                           train_users_df[author_features][train_users_df.index.isin(labeled_indexes)].reset_index(drop=True)], axis=1)        \n",
    "    print('Added author features')\n",
    "#y_labeled = y[labeled_indexes]\n",
    "\n",
    "if selected_classifier == 'SVM':\n",
    "    clf = svm.SVC(kernel='linear', C=1, random_state=0, probability=True)\n",
    "elif selected_classifier == 'RandomForest':\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    \n",
    "clf.fit(X_labeled, y_labeled)\n",
    "\n",
    "svm_coef = clf.coef_[0]\n",
    "\n",
    "unlabeled_indexes = validation_users_df.index\n",
    "\n",
    "X_unlabeled = X[unlabeled_indexes]\n",
    "if with_author_features:\n",
    "    X_unlabeled = pd.concat([pd.DataFrame(X_unlabeled.toarray()), \n",
    "                           healthcare_workers_df[author_features][healthcare_workers_df.index.isin(unlabeled_indexes)].reset_index(drop=True)], axis=1)        \n",
    "    print('Added author features')\n",
    "\n",
    "pred = clf.predict_proba(X_unlabeled)\n",
    "\n",
    "predict_pobabilities = pred[:, 1]\n",
    "\n",
    "df = pd.DataFrame(predict_pobabilities, columns=['predict_pob'])\n",
    "\n",
    "df['automatic_prediction'] = df['predict_pob'].apply(lambda x:1 if x>=0.5 else 0)\n",
    "predictions_series = df['automatic_prediction']\n",
    "\n",
    "accuracy_scores.append(accuracy_score(healthcare_workers_df.iloc[unlabeled_indexes]['author_type_numeric'].astype('int'), df['automatic_prediction']))\n",
    "print('Got {} accuracy scores'.format(len(accuracy_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_coef[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = pd.Series(accuracy_scores)\n",
    "print('Mean accuracy:', accuracy_scores.mean())\n",
    "print('Std accuracy:', accuracy_scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
