{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "import pyLDAvis.gensim\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from bidi.algorithm import get_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\lda_corpora\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT'\n",
    "output_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\lda_models\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_34TOPICS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda(corpus, model_dict, num_topics, num_passes, chunksize, eval_every):\n",
    "    return LdaMulticore(\n",
    "                            corpus=corpus,\n",
    "                            id2word=model_dict,\n",
    "                            random_state=100,\n",
    "                            num_topics=num_topics,\n",
    "                            passes=num_passes,\n",
    "                            chunksize=chunksize,\n",
    "                            batch=False,\n",
    "                            alpha='asymmetric',\n",
    "                            decay=0.5,\n",
    "                            offset=64,\n",
    "                            eta=None,\n",
    "                            eval_every=eval_every,\n",
    "                            iterations=100,\n",
    "                            gamma_threshold=0.001,\n",
    "                            per_word_topics=True,\n",
    "                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\d\n",
      "<ipython-input-5-994cc77e6a6e>:2: DeprecationWarning: invalid escape sequence \\d\n",
      "  p = re.compile(\"(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity\")\n"
     ]
    }
   ],
   "source": [
    "def save_convergence_plot(log_dir):\n",
    "    p = re.compile(\"(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity\")\n",
    "    matches = [p.findall(l) for l in open('{}/training.log'.format(log_dir))]\n",
    "    matches = [m for m in matches if len(m) > 0]\n",
    "    tuples = [t[0] for t in matches]\n",
    "    perplexity = [float(t[1]) for t in tuples]\n",
    "    liklihood = [float(t[0]) for t in tuples]\n",
    "    iter = list(range(0, len(tuples) * 10, 10))\n",
    "    plt.plot(iter, liklihood, c='black')\n",
    "    plt.ylabel('log liklihood')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.title('Topic Model Convergence')\n",
    "    plt.grid()\n",
    "    plt.savefig('{}/convergence_likihood.png'.format(log_dir))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_cloud(model_dict, lda_model, num_topics, directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    for topic in range(0, num_topics):\n",
    "                    topic_terms = lda_model.get_topic_terms(topic, 20)\n",
    "                    word_frequency_dict = {model_dict[word_id]:freq for (word_id, freq) in topic_terms}\n",
    "                \n",
    "                    # make wordcloud\n",
    "                    wc = WordCloud(background_color='black', width=1000, height=1000, max_words=20).generate_from_frequencies(word_frequency_dict)\n",
    "                    wc.to_file('{}/topic{}.png'.format(directory, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " import operator\n",
    "def get_document_topics(corpus, lda):\n",
    "    topics = []\n",
    "    for i, document in enumerate(corpus):\n",
    "        corpus_dict = {topic:prob for (topic, prob) in lda.get_document_topics(corpus[i])}\n",
    "        topics.append(max(corpus_dict.items(), key=operator.itemgetter(1))[0])\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_topics(output_path, corpus, model_dict, num_topics, num_passes, chunksize=15000, eval_every=10, print_results=False,\n",
    "                  save_wordclouds=False, hebrew=False):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    logging.basicConfig(filename='{}/training.log'.format(output_path), format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)\n",
    "    \n",
    "    T = time.time()\n",
    "    lda_model = train_lda(corpus, model_dict, num_topics, num_passes, chunksize, eval_every)\n",
    "    T = time.time() - T\n",
    "\n",
    "    print('Finished {} topics and {} passes ({} seconds)'.format(num_topics, num_passes, T))\n",
    "    if print_results:\n",
    "        print(lda_model.print_topics(-1))\n",
    "    lda_model.save('{}/lda.model'.format(output_path))\n",
    "    print('Saved to {}/lda.model'.format(output_path))\n",
    "    save_convergence_plot(output_path)\n",
    "    \n",
    "    if save_wordclouds:\n",
    "        for topic in range(0, num_topics):\n",
    "            topic_terms = lda_model.get_topic_terms(topic, 20)\n",
    "            if not hebrew:\n",
    "                word_frequency_dict = {model_dict[word_id]:freq for (word_id, freq) in topic_terms}\n",
    "            else:\n",
    "                word_frequency_dict = {get_display(model_dict[word_id]):freq for (word_id, freq) in topic_terms}\n",
    "                \n",
    "            # make wordcloud\n",
    "            if not hebrew:\n",
    "                wc = WordCloud(background_color='black', width=1000, height=1000, max_words=20).generate_from_frequencies(word_frequency_dict)\n",
    "            else:\n",
    "                wc = WordCloud(background_color='black', width=1000, height=1000, max_words=20, font_path=r'C:\\WINDOWS\\FONTS\\AHRONBD.TTF').generate_from_frequencies(word_frequency_dict)\n",
    "            wc.to_file('{}/topic{}.png'.format(output_path, topic))\n",
    "            \n",
    "    return lda_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_topic_term_ids(lda_model, num_topics, num_terms):\n",
    "    terms = []\n",
    "    for topic in range(0, num_topics):\n",
    "        terms.append([word for (word, freq) in lda_model.get_topic_terms(topic, num_terms)])\n",
    "    return terms\n",
    "\n",
    "def get_all_topic_terms(model_dict, lda_model, num_topics, num_terms):\n",
    "    terms = []\n",
    "    for topic in range(0, num_topics):\n",
    "        terms.append([model_dict[word] for (word, freq) in lda_model.get_topic_terms(topic, num_terms)])\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "\n",
    "corpus = MmCorpus('{}/corpus.mm'.format(corpus_path))\n",
    "model_dict = Dictionary.load('{}/dict.id2word'.format(corpus_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if eval_every is NOT 0, restart kernel before RE-using\n",
    "\n",
    "model = detect_topics(output_path, corpus, model_dict, 34, 150, eval_every=0, chunksize=130000, print_results=False, save_wordclouds=True, hebrew=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
