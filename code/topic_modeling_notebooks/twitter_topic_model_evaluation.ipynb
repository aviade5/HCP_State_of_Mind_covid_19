{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_model_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\with_keywords\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_WITH_KEYWORDS_35TOPICS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded twitter model, corpus, dictionary in 5.0683274269104 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "twitter_corpus = MmCorpus('{}/corpus.mm'.format(twitter_model_path))\n",
    "twitter_dict = Dictionary.load('{}/dict.id2word'.format(twitter_model_path))\n",
    "twitter_model = LdaModel.load('{}/lda.model'.format(twitter_model_path))\n",
    "\n",
    "T = time.time() - T\n",
    "print('Loaded twitter model, corpus, dictionary in {} seconds'.format(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.39706012472985397 - time elapsed: 420.45825242996216 seconds\n",
      "Computed coherence scores in 633.3070476055145 seconds\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "texts = []\n",
    "for bow in twitter_corpus:\n",
    "    texts.append([twitter_dict[word_id] for (word_id, _) in bow])\n",
    "    \n",
    "# available coherence measures: u_mass, c_v, c_uci, c_npmi\n",
    "# explanations can be found here: \n",
    "# https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "\n",
    "#coherence_measures = ['u_mass', 'c_v', 'c_uci', 'c_npmi']\n",
    "coherence_measures = ['c_v']\n",
    "    \n",
    "for coherence_measure in coherence_measures:\n",
    "    cT = time.time()\n",
    "    print(f'Calculating coherence measure {coherence_measure}...')\n",
    "    coherence_model = CoherenceModel(model=twitter_model, texts=texts, corpus=twitter_corpus, dictionary=twitter_dict, coherence=coherence_measure)\n",
    "    coherence_lda = coherence_model.get_coherence()\n",
    "    \n",
    "    print(f'{coherence_measure} score: {coherence_lda} - time elapsed: {time.time() - cT} seconds')\n",
    "\n",
    "print(f'Computed coherence scores in {time.time() - T} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM TOPICS: 5\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.135768175125122 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.2757139829980706 - time elapsed: 109.59741139411926 seconds\n",
      "Computed coherence scores in 163.90041303634644 seconds\n",
      "\n",
      "NUM TOPICS: 5\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 1.7382838726043701 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.2629636404671189 - time elapsed: 118.65538430213928 seconds\n",
      "Computed coherence scores in 174.9771761894226 seconds\n",
      "\n",
      "NUM TOPICS: 5\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.2093076705932617 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.25077029108037235 - time elapsed: 114.57622241973877 seconds\n",
      "Computed coherence scores in 176.8120837211609 seconds\n",
      "\n",
      "NUM TOPICS: 10\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.3603506088256836 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.38006427412085586 - time elapsed: 123.89144277572632 seconds\n",
      "Computed coherence scores in 186.90679669380188 seconds\n",
      "\n",
      "NUM TOPICS: 10\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 2.7779541015625 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.3543055901402824 - time elapsed: 114.92308783531189 seconds\n",
      "Computed coherence scores in 176.89899826049805 seconds\n",
      "\n",
      "NUM TOPICS: 10\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.679619073867798 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.37359708518597073 - time elapsed: 113.04171705245972 seconds\n",
      "Computed coherence scores in 166.82103729248047 seconds\n",
      "\n",
      "NUM TOPICS: 15\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 3.144965171813965 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.40904937100931316 - time elapsed: 120.5435516834259 seconds\n",
      "Computed coherence scores in 174.17122292518616 seconds\n",
      "\n",
      "NUM TOPICS: 15\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 3.577979564666748 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.43703707484122184 - time elapsed: 116.24756097793579 seconds\n",
      "Computed coherence scores in 171.324942111969 seconds\n",
      "\n",
      "NUM TOPICS: 15\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 1.940030813217163 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4312924948817054 - time elapsed: 114.72718977928162 seconds\n",
      "Computed coherence scores in 168.607976436615 seconds\n",
      "\n",
      "NUM TOPICS: 20\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.265235185623169 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.45534055724918215 - time elapsed: 118.13504934310913 seconds\n",
      "Computed coherence scores in 170.54105520248413 seconds\n",
      "\n",
      "NUM TOPICS: 20\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 3.193760871887207 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.47430481120448037 - time elapsed: 119.54460144042969 seconds\n",
      "Computed coherence scores in 173.92076802253723 seconds\n",
      "\n",
      "NUM TOPICS: 20\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 3.3893496990203857 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.45173635858390215 - time elapsed: 116.79944968223572 seconds\n",
      "Computed coherence scores in 171.0255355834961 seconds\n",
      "\n",
      "NUM TOPICS: 25\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 3.051194190979004 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.46534341308249283 - time elapsed: 117.9804790019989 seconds\n",
      "Computed coherence scores in 169.7166132926941 seconds\n",
      "\n",
      "NUM TOPICS: 25\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 3.5796566009521484 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4781837441298428 - time elapsed: 119.88438653945923 seconds\n",
      "Computed coherence scores in 175.38103437423706 seconds\n",
      "\n",
      "NUM TOPICS: 25\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.929952383041382 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4717183453297706 - time elapsed: 127.70034670829773 seconds\n",
      "Computed coherence scores in 192.3562970161438 seconds\n",
      "\n",
      "NUM TOPICS: 26\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 3.4549295902252197 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.48268718175600933 - time elapsed: 123.09446001052856 seconds\n",
      "Computed coherence scores in 182.26772832870483 seconds\n",
      "\n",
      "NUM TOPICS: 26\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 3.1564817428588867 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.44809642219995854 - time elapsed: 113.64567375183105 seconds\n",
      "Computed coherence scores in 170.9812273979187 seconds\n",
      "\n",
      "NUM TOPICS: 26\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.2957332134246826 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.47663769650498394 - time elapsed: 113.39967346191406 seconds\n",
      "Computed coherence scores in 166.9057834148407 seconds\n",
      "\n",
      "NUM TOPICS: 27\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.251046657562256 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.47793994376741217 - time elapsed: 113.56335711479187 seconds\n",
      "Computed coherence scores in 164.98335599899292 seconds\n",
      "\n",
      "NUM TOPICS: 27\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 2.4516193866729736 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.46205711098776775 - time elapsed: 110.57128691673279 seconds\n",
      "Computed coherence scores in 159.3423900604248 seconds\n",
      "\n",
      "NUM TOPICS: 27\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.0003323554992676 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4646344892986854 - time elapsed: 106.9879834651947 seconds\n",
      "Computed coherence scores in 158.85906100273132 seconds\n",
      "\n",
      "NUM TOPICS: 28\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.7966959476470947 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4511096253955256 - time elapsed: 121.64251160621643 seconds\n",
      "Computed coherence scores in 177.9188516139984 seconds\n",
      "\n",
      "NUM TOPICS: 28\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 2.7670207023620605 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4423913330679365 - time elapsed: 123.49863576889038 seconds\n",
      "Computed coherence scores in 185.23547530174255 seconds\n",
      "\n",
      "NUM TOPICS: 28\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.27958083152771 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.43551991512141075 - time elapsed: 111.0584135055542 seconds\n",
      "Computed coherence scores in 162.82575154304504 seconds\n",
      "\n",
      "NUM TOPICS: 29\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.4226582050323486 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4505091232374725 - time elapsed: 123.56729674339294 seconds\n",
      "Computed coherence scores in 187.87533807754517 seconds\n",
      "\n",
      "NUM TOPICS: 29\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 2.718078374862671 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.44633879225945583 - time elapsed: 123.52435898780823 seconds\n",
      "Computed coherence scores in 178.21322417259216 seconds\n",
      "\n",
      "NUM TOPICS: 29\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.4445786476135254 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4485813125834697 - time elapsed: 121.64465832710266 seconds\n",
      "Computed coherence scores in 173.6749668121338 seconds\n",
      "\n",
      "NUM TOPICS: 30\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.7738258838653564 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.4327859143472997 - time elapsed: 119.7949435710907 seconds\n",
      "Computed coherence scores in 173.01386141777039 seconds\n",
      "\n",
      "NUM TOPICS: 30\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 2.3136844635009766 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.41732672630585854 - time elapsed: 118.29557657241821 seconds\n",
      "Computed coherence scores in 171.6894187927246 seconds\n",
      "\n",
      "NUM TOPICS: 30\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.386969566345215 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.42679646053690606 - time elapsed: 120.89423108100891 seconds\n",
      "Computed coherence scores in 175.34726643562317 seconds\n",
      "\n",
      "NUM TOPICS: 35\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.3233394622802734 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.36432752467169305 - time elapsed: 121.87988591194153 seconds\n",
      "Computed coherence scores in 181.57917714118958 seconds\n",
      "\n",
      "NUM TOPICS: 35\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 3.3430306911468506 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.3472963572656486 - time elapsed: 111.61602520942688 seconds\n",
      "Computed coherence scores in 169.73969888687134 seconds\n",
      "\n",
      "NUM TOPICS: 35\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 1.7422552108764648 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.353928393229299 - time elapsed: 122.87826752662659 seconds\n",
      "Computed coherence scores in 182.12020993232727 seconds\n",
      "\n",
      "NUM TOPICS: 40\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.1780812740325928 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.35368526217645246 - time elapsed: 136.34238290786743 seconds\n",
      "Computed coherence scores in 194.7956941127777 seconds\n",
      "\n",
      "NUM TOPICS: 40\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 2.240103244781494 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.3581978581262185 - time elapsed: 142.98242211341858 seconds\n",
      "Computed coherence scores in 206.60028266906738 seconds\n",
      "\n",
      "NUM TOPICS: 40\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.3273518085479736 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.3345044528809871 - time elapsed: 139.18635368347168 seconds\n",
      "Computed coherence scores in 197.32845854759216 seconds\n",
      "\n",
      "NUM TOPICS: 45\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.3109195232391357 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.38087522606126917 - time elapsed: 137.58132576942444 seconds\n",
      "Computed coherence scores in 200.1940336227417 seconds\n",
      "\n",
      "NUM TOPICS: 45\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 2.087013006210327 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.32986774077174924 - time elapsed: 142.6871771812439 seconds\n",
      "Computed coherence scores in 203.34220814704895 seconds\n",
      "\n",
      "NUM TOPICS: 45\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.358942985534668 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.3787100033674415 - time elapsed: 137.08862209320068 seconds\n",
      "Computed coherence scores in 195.046532869339 seconds\n",
      "\n",
      "NUM TOPICS: 50\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.2662386894226074 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.3834214944934007 - time elapsed: 145.47106218338013 seconds\n",
      "Computed coherence scores in 205.6108374595642 seconds\n",
      "\n",
      "NUM TOPICS: 50\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 3.011484384536743 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.34535409922809346 - time elapsed: 142.5672960281372 seconds\n",
      "Computed coherence scores in 205.0004870891571 seconds\n",
      "\n",
      "NUM TOPICS: 50\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 2.9200501441955566 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.34558983583277547 - time elapsed: 146.64286136627197 seconds\n",
      "Computed coherence scores in 201.10560417175293 seconds\n",
      "\n",
      "NUM TOPICS: 55\tSAMPLE: 1\n",
      "Loaded twitter model, corpus, dictionary in 2.5802483558654785 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.3481135870200368 - time elapsed: 133.90087890625 seconds\n",
      "Computed coherence scores in 192.67117309570312 seconds\n",
      "\n",
      "NUM TOPICS: 55\tSAMPLE: 2\n",
      "Loaded twitter model, corpus, dictionary in 3.344829559326172 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.3122281232484927 - time elapsed: 148.10191226005554 seconds\n",
      "Computed coherence scores in 212.72917485237122 seconds\n",
      "\n",
      "NUM TOPICS: 55\tSAMPLE: 3\n",
      "Loaded twitter model, corpus, dictionary in 3.1137070655822754 seconds\n",
      "Calculating coherence measure c_v...\n",
      "c_v score: 0.333240590090982 - time elapsed: 148.17589807510376 seconds\n",
      "Computed coherence scores in 204.1580765247345 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# TEMPORARY\n",
    "\n",
    "for num_topics in [5, 10, 15, 20, 25, 26, 27, 28, 29, 30, 35, 40, 45, 50, 55]:\n",
    "    for sample_id in [1, 2, 3]:\n",
    "        twitter_model_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\with_keywords\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_WITH_KEYWORDS_SAMPLE{}_{}TOPICS'.format(sample_id, num_topics)\n",
    "\n",
    "        print('NUM TOPICS: {}\\tSAMPLE: {}'.format(num_topics, sample_id))\n",
    "        \n",
    "        T = time.time()\n",
    "\n",
    "        twitter_corpus = MmCorpus('{}/corpus.mm'.format(twitter_model_path))\n",
    "        twitter_dict = Dictionary.load('{}/dict.id2word'.format(twitter_model_path))\n",
    "        twitter_model = LdaModel.load('{}/lda.model'.format(twitter_model_path))\n",
    "\n",
    "        T = time.time() - T\n",
    "        print('Loaded twitter model, corpus, dictionary in {} seconds'.format(T))\n",
    "        \n",
    "        T = time.time()\n",
    "\n",
    "        texts = []\n",
    "        for bow in twitter_corpus:\n",
    "            texts.append([twitter_dict[word_id] for (word_id, _) in bow])\n",
    "\n",
    "        # available coherence measures: u_mass, c_v, c_uci, c_npmi\n",
    "        # explanations can be found here: \n",
    "        # https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "\n",
    "        #coherence_measures = ['u_mass', 'c_v', 'c_uci', 'c_npmi']\n",
    "        coherence_measures = ['c_v']\n",
    "\n",
    "        for coherence_measure in coherence_measures:\n",
    "            cT = time.time()\n",
    "            print(f'Calculating coherence measure {coherence_measure}...')\n",
    "            coherence_model = CoherenceModel(model=twitter_model, texts=texts, corpus=twitter_corpus, dictionary=twitter_dict, coherence=coherence_measure)\n",
    "            coherence_lda = coherence_model.get_coherence()\n",
    "\n",
    "            print(f'{coherence_measure} score: {coherence_lda} - time elapsed: {time.time() - cT} seconds')\n",
    "\n",
    "        print(f'Computed coherence scores in {time.time() - T} seconds')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = time.time()\n",
    "\n",
    "# this takes much longer than coherence for some reason\n",
    "\n",
    "print('Perplexity:', twitter_model.log_perplexity(twitter_corpus))\n",
    "\n",
    "print(f'Computed perplexity in {time.time() - T} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMI between samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_topic_id(bow, model):\n",
    "    return sorted(model.get_document_topics(bow), key=lambda tup: tup[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute confusion matrix\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    \n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "import json\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "\n",
    "model1_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE1_45TOPICS'\n",
    "model2_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE2_45TOPICS'\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1 = LdaModel.load(f'{model1_path}/lda.model')\n",
    "model2 = LdaModel.load(f'{model2_path}/lda.model')\n",
    "\n",
    "with open(f'{model1_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model1_id_bow_dict = json.load(f)\n",
    "    \n",
    "with open(f'{model2_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model2_id_bow_dict = json.load(f)\n",
    "\n",
    "common_tweets = list(set(model1_id_bow_dict.keys()) & set(model2_id_bow_dict.keys()))\n",
    "\n",
    "print(f'Loaded models in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Model 1 # tweets: {len(model1_id_bow_dict)}, model 2 # tweets: {len(model2_id_bow_dict)}, # common tweets: {len(common_tweets)}')\n",
    "\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1_tweet_topics = [get_bow_topic_id(model1_id_bow_dict[tweet], model1) for tweet in common_tweets]\n",
    "model2_tweet_topics = [get_bow_topic_id(model2_id_bow_dict[tweet], model2) for tweet in common_tweets]\n",
    "\n",
    "print(f'Created inputs in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Purity: {purity_score(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'NMI: {nmi(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'ARI: {ari(model1_tweet_topics, model2_tweet_topics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "import json\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "\n",
    "model1_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE1_45TOPICS'\n",
    "model2_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE3_45TOPICS'\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1 = LdaModel.load(f'{model1_path}/lda.model')\n",
    "model2 = LdaModel.load(f'{model2_path}/lda.model')\n",
    "\n",
    "with open(f'{model1_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model1_id_bow_dict = json.load(f)\n",
    "    \n",
    "with open(f'{model2_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model2_id_bow_dict = json.load(f)\n",
    "\n",
    "common_tweets = list(set(model1_id_bow_dict.keys()) & set(model2_id_bow_dict.keys()))\n",
    "\n",
    "print(f'Loaded models in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Model 1 # tweets: {len(model1_id_bow_dict)}, model 2 # tweets: {len(model2_id_bow_dict)}, # common tweets: {len(common_tweets)}')\n",
    "\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1_tweet_topics = [get_bow_topic_id(model1_id_bow_dict[tweet], model1) for tweet in common_tweets]\n",
    "model2_tweet_topics = [get_bow_topic_id(model2_id_bow_dict[tweet], model2) for tweet in common_tweets]\n",
    "\n",
    "print(f'Created inputs in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Purity: {purity_score(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'NMI: {nmi(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'ARI: {ari(model1_tweet_topics, model2_tweet_topics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "import json\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "\n",
    "model1_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE2_45TOPICS'\n",
    "model2_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE3_45TOPICS'\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1 = LdaModel.load(f'{model1_path}/lda.model')\n",
    "model2 = LdaModel.load(f'{model2_path}/lda.model')\n",
    "\n",
    "with open(f'{model1_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model1_id_bow_dict = json.load(f)\n",
    "    \n",
    "with open(f'{model2_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model2_id_bow_dict = json.load(f)\n",
    "\n",
    "common_tweets = list(set(model1_id_bow_dict.keys()) & set(model2_id_bow_dict.keys()))\n",
    "\n",
    "print(f'Loaded models in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Model 1 # tweets: {len(model1_id_bow_dict)}, model 2 # tweets: {len(model2_id_bow_dict)}, # common tweets: {len(common_tweets)}')\n",
    "\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1_tweet_topics = [get_bow_topic_id(model1_id_bow_dict[tweet], model1) for tweet in common_tweets]\n",
    "model2_tweet_topics = [get_bow_topic_id(model2_id_bow_dict[tweet], model2) for tweet in common_tweets]\n",
    "\n",
    "print(f'Created inputs in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Purity: {purity_score(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'NMI: {nmi(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'ARI: {ari(model1_tweet_topics, model2_tweet_topics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "import json\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "\n",
    "model1_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE1_45TOPICS'\n",
    "model2_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_45TOPICS'\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1 = LdaModel.load(f'{model1_path}/lda.model')\n",
    "model2 = LdaModel.load(f'{model2_path}/lda.model')\n",
    "\n",
    "with open(f'{model1_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model1_id_bow_dict = json.load(f)\n",
    "    \n",
    "with open(f'{model2_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model2_id_bow_dict = json.load(f)\n",
    "\n",
    "common_tweets = list(set(model1_id_bow_dict.keys()) & set(model2_id_bow_dict.keys()))\n",
    "\n",
    "print(f'Loaded models in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Model 1 # tweets: {len(model1_id_bow_dict)}, model 2 # tweets: {len(model2_id_bow_dict)}, # common tweets: {len(common_tweets)}')\n",
    "\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1_tweet_topics = [get_bow_topic_id(model1_id_bow_dict[tweet], model1) for tweet in common_tweets]\n",
    "model2_tweet_topics = [get_bow_topic_id(model2_id_bow_dict[tweet], model2) for tweet in common_tweets]\n",
    "\n",
    "print(f'Created inputs in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Purity: {purity_score(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'NMI: {nmi(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'ARI: {ari(model1_tweet_topics, model2_tweet_topics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "import json\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "\n",
    "model1_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE2_45TOPICS'\n",
    "model2_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_45TOPICS'\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1 = LdaModel.load(f'{model1_path}/lda.model')\n",
    "model2 = LdaModel.load(f'{model2_path}/lda.model')\n",
    "\n",
    "with open(f'{model1_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model1_id_bow_dict = json.load(f)\n",
    "    \n",
    "with open(f'{model2_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model2_id_bow_dict = json.load(f)\n",
    "\n",
    "common_tweets = list(set(model1_id_bow_dict.keys()) & set(model2_id_bow_dict.keys()))\n",
    "\n",
    "print(f'Loaded models in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Model 1 # tweets: {len(model1_id_bow_dict)}, model 2 # tweets: {len(model2_id_bow_dict)}, # common tweets: {len(common_tweets)}')\n",
    "\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1_tweet_topics = [get_bow_topic_id(model1_id_bow_dict[tweet], model1) for tweet in common_tweets]\n",
    "model2_tweet_topics = [get_bow_topic_id(model2_id_bow_dict[tweet], model2) for tweet in common_tweets]\n",
    "\n",
    "print(f'Created inputs in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Purity: {purity_score(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'NMI: {nmi(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'ARI: {ari(model1_tweet_topics, model2_tweet_topics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora.mmcorpus import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "import json\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami\n",
    "\n",
    "model1_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_SAMPLE3_45TOPICS'\n",
    "model2_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\hpc_generated\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_NO_RETWEETS_45TOPICS'\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1 = LdaModel.load(f'{model1_path}/lda.model')\n",
    "model2 = LdaModel.load(f'{model2_path}/lda.model')\n",
    "\n",
    "with open(f'{model1_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model1_id_bow_dict = json.load(f)\n",
    "    \n",
    "with open(f'{model2_path}/post_id_bow_dict.json', 'r') as f:\n",
    "    model2_id_bow_dict = json.load(f)\n",
    "\n",
    "common_tweets = list(set(model1_id_bow_dict.keys()) & set(model2_id_bow_dict.keys()))\n",
    "\n",
    "print(f'Loaded models in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Model 1 # tweets: {len(model1_id_bow_dict)}, model 2 # tweets: {len(model2_id_bow_dict)}, # common tweets: {len(common_tweets)}')\n",
    "\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model1_tweet_topics = [get_bow_topic_id(model1_id_bow_dict[tweet], model1) for tweet in common_tweets]\n",
    "model2_tweet_topics = [get_bow_topic_id(model2_id_bow_dict[tweet], model2) for tweet in common_tweets]\n",
    "\n",
    "print(f'Created inputs in {time.time() - T} seconds')\n",
    "\n",
    "print(f'Purity: {purity_score(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'NMI: {nmi(model1_tweet_topics, model2_tweet_topics)}')\n",
    "print(f'ARI: {ari(model1_tweet_topics, model2_tweet_topics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
