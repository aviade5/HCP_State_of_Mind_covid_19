{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Sentiment Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "database_path = r\"C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\databases\\bad_actors_Coronavirus_Project_POI_Followers_13-06-20.db\"\n",
    "model_path = r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\output_data\\POI_Followers_13-06-20'\n",
    "output_path = r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\output_data\\sentiment_analysis\\POI_Followers_13-06-20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('{}/post_id_bow_dict.json'.format(model_path), 'r') as file_handle:\n",
    "    tweet_ids = json.load(file_handle).keys()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import time\n",
    "\n",
    "tweet_id_content_dict = {}\n",
    "\n",
    "T = time.time()\n",
    "conn = sql.connect(database_path)\n",
    "cur = conn.cursor()\n",
    "query = 'SELECT post_id, content FROM posts'\n",
    "results = cur.execute(query)\n",
    "\n",
    "result = results.fetchone()\n",
    "while result:\n",
    "    if result[0] in tweet_ids:\n",
    "        tweet_id_content_dict[result[0]] = result[1]\n",
    "    result = results.fetchone()\n",
    "\n",
    "print('Extracted required sub-dictionary in {} seconds'.format(time.time() - T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_compound_value(post):\n",
    "    score = analyzer.polarity_scores(post)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T = time.time()\n",
    "tweet_id_sentiment_dict = {}\n",
    "for i, (tweet_id, content) in enumerate(tweet_id_content_dict.items()):\n",
    "    if i % 200000 == 0:\n",
    "        print('Finished {}/{} tweets'.format(i, len(tweet_id_content_dict)))\n",
    "    tweet_id_sentiment_dict[tweet_id] = get_sentiment_compound_value(content)\n",
    "    \n",
    "print('Finished sentiment analysis for {} tweets in {} seconds'.format(len(tweet_id_sentiment_dict), time.time() - T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('{}/tweet_id_sentiment_map.json'.format(output_path), 'w') as file_handle:\n",
    "    json.dump(tweet_id_sentiment_dict, file_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precise emotion recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_path = r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\databases\\bad_actors_Coronavirus_Project_POI_Followers_13-06-20.db'\n",
    "model_path = r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\output_data\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_25TOPICS'\n",
    "labeled_authors_csv_path = r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\databases\\person_organization_classification\\labeled_authors_V10.csv'\n",
    "unlabeled_authors_csv_path = r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\databases\\person_organization_classification\\all_unlabeled_predictions_using_description_and_SVM_classifier_inbalanced_to_label_V10.csv'\n",
    "tweet_emotions_path = r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\output_data\\sentiment_analysis\\POI_Followers_13-06-20\\unlabeled_author_tweet_emotions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "    \n",
    "set_keras_backend('theano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from emotion_predictor import EmotionPredictor\n",
    "import time\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "model = EmotionPredictor(classification='ekman', setting='mc')\n",
    "\n",
    "print(f'Loaded emotion predictor model in {time.time() - T} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labeled_authors_df = pd.read_csv(labeled_authors_csv_path)\n",
    "unlabeled_authors_df = pd.read_csv(unlabeled_authors_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CONFIDENCE_PERCENTILE = 0.4\n",
    "\n",
    "person_authors = list(labeled_authors_df[labeled_authors_df['author_sub_type'] == 'PERSON']['author_screen_name'])\n",
    "person_sorted_by_confidence = unlabeled_authors_df[unlabeled_authors_df['str_automatic_prediction'] == 'PERSON'].sort_values(by=['confidence_to_organization'], ascending=True)\n",
    "max_organization_confidence = person_sorted_by_confidence.quantile(CONFIDENCE_PERCENTILE)[0]\n",
    "percentile_person_authors = person_sorted_by_confidence[unlabeled_authors_df['confidence_to_organization'] < max_organization_confidence]\n",
    "\n",
    "person_authors = list(percentile_person_authors['author_screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "\n",
    "conn = sql.connect(db_path)\n",
    "\n",
    "pd.read_sql('SELECT COUNT(*) FROM posts', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ast import literal_eval as make_tuple\n",
    "\n",
    "if os.path.exists(tweet_emotions_path):\n",
    "    with open(tweet_emotions_path, 'r') as file_handle:\n",
    "        tweet_emotions = json.load(file_handle)\n",
    "    tweet_emotions = {tweet_id : make_tuple(tuple_str) for (tweet_id, tuple_str) in tweet_emotions.items()}\n",
    "    \n",
    "    print(f'Loaded tweet emotion dictionary with {len(tweet_emotions)} tweets')\n",
    "else:\n",
    "    tweet_emotions = {}\n",
    "    print('No tweet emotion dictionary found. Creating brand new one.')\n",
    "\n",
    "con = sql.connect(db_path)\n",
    "cur = con.cursor()\n",
    "query = 'SELECT post_id, content FROM posts WHERE author = \\'{}\\''\n",
    "\n",
    "for person in tqdm(person_authors):\n",
    "    T = time.time()\n",
    "    results = cur.execute(query.format(person))\n",
    "    results = results.fetchall()\n",
    "    print(f'Fetched {len(results)} tweets for author {person} in {time.time() - T} seconds')\n",
    "    \n",
    "    results = [result for result in results if result[0] not in tweet_emotions]\n",
    "    print(f'Out of these {len(results)} are not present in dictionary')\n",
    "    \n",
    "    if not results:\n",
    "        print('Skipping.')\n",
    "        continue\n",
    "    \n",
    "    T = time.time()\n",
    "    \n",
    "    tweets = [result[1] for result in results]\n",
    "    emotion_probs = model.predict_probabilities(tweets)\n",
    "    \n",
    "    for i, result in enumerate(tqdm(results)):\n",
    "        tweet_emotion_probs = tuple(emotion_probs.iloc[i][1:])\n",
    "        \n",
    "        tweet_emotions[result[0]] = tweet_emotion_probs\n",
    "    \n",
    "    print(emotion_probs)\n",
    "    \n",
    "    print(f'Got emotion probabilities in {time.time() - T} seconds')\n",
    "    \n",
    "    with open(tweet_emotions_path, 'w') as file_handle:\n",
    "        serializable_dict = {tweet_id : str(tup) for (tweet_id, tup) in tweet_emotions.items()}\n",
    "        json.dump(serializable_dict, file_handle)\n",
    "\n",
    "    print('Dictionary updated.')\n",
    "        \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(tweet_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before and After Emotions - Load Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ast import literal_eval as make_tuple\n",
    "\n",
    "with open(r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\output_data\\sentiment_analysis\\POI_Followers_13-06-20\\labeled_author_tweet_emotions.json', 'r') as f:\n",
    "    tweet_emotions = json.load(f) \n",
    "    \n",
    "tweet_emotions = {tweet_id : make_tuple(tup_str) for tweet_id, tup_str in tweet_emotions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RECOGNITION_THRESHOLD = 0.9\n",
    "\n",
    "def get_emotion_from_prob_list(prob_list):\n",
    "    if max(prob_list) < RECOGNITION_THRESHOLD:\n",
    "        return 'None'\n",
    "    return ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise'][prob_list.index(max(prob_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discrete_tweet_emotions = {tweet_id : get_emotion_from_prob_list(prob_list) for tweet_id, prob_list in tweet_emotions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discrete_tweet_emotions = {tweet_id : emotion for tweet_id, emotion in discrete_tweet_emotions.items() if emotion != 'None'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(discrete_tweet_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
    "colors = ['red', 'brown', 'orange', 'green', 'grey', 'blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotions_only = [emotion for _, emotion in discrete_tweet_emotions.items()]\n",
    "all_tweets_sizes = [emotions_only.count('Anger'), emotions_only.count('Disgust'), emotions_only.count('Fear'),\n",
    "         emotions_only.count('Joy'), emotions_only.count('Sadness'), emotions_only.count('Surprise')]\n",
    "\n",
    "print(f'{len(person_authors)} authors total')\n",
    "print(f'{len(emotions_only)} tweets total for threshold {RECOGNITION_THRESHOLD}')\n",
    "print(' '.join([f'{label}: {100.0 * emotions_only.count(label) / len(emotions_only):.2f}%' for label in labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before and After Pandemic - Automatic Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "middle_date = datetime.strptime('2019-12-31 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "con = sql.connect(db_path)\n",
    "cur = con.cursor()\n",
    "\n",
    "before_tweets = []\n",
    "\n",
    "for tweet in tqdm(discrete_tweet_emotions):\n",
    "    query = f'SELECT date FROM posts WHERE post_id = \\'{tweet}\\''\n",
    "    date = cur.execute(query).fetchall()[0][0]\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    if date <= middle_date:\n",
    "        before_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before_discrete_tweet_emotions = {tweet_id : emotion for tweet_id, emotion in discrete_tweet_emotions.items() if tweet_id in before_tweets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotions_only = [emotion for _, emotion in before_discrete_tweet_emotions.items()]\n",
    "before_pandemic_sizes = [emotions_only.count('Anger'), emotions_only.count('Disgust'), emotions_only.count('Fear'),\n",
    "         emotions_only.count('Joy'), emotions_only.count('Sadness'), emotions_only.count('Surprise')]\n",
    "\n",
    "print(f'{len(person_authors)} authors total')\n",
    "print(f'{len(emotions_only)} tweets total for threshold {RECOGNITION_THRESHOLD}')\n",
    "print(' '.join([f'{label}: {100.0 * emotions_only.count(label) / len(emotions_only):.2f}%' for label in labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "after_discrete_tweet_emotions = {tweet_id : emotion for tweet_id, emotion in discrete_tweet_emotions.items() if tweet_id not in before_tweets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotions_only = [emotion for _, emotion in after_discrete_tweet_emotions.items()]\n",
    "during_pandemic_sizes = [emotions_only.count('Anger'), emotions_only.count('Disgust'), emotions_only.count('Fear'),\n",
    "         emotions_only.count('Joy'), emotions_only.count('Sadness'), emotions_only.count('Surprise')]\n",
    "\n",
    "print(f'{len(person_authors)} authors total')\n",
    "print(f'{len(emotions_only)} tweets total for threshold {RECOGNITION_THRESHOLD}')\n",
    "print(' '.join([f'{label}: {100.0 * emotions_only.count(label) / len(emotions_only):.2f}%' for label in labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "ax[0].pie(all_tweets_sizes, colors=colors, autopct='%1.1f%%', shadow=True, radius=1.2)\n",
    "ax[0].set_title(f'All tweets ({sum(all_tweets_sizes)})')\n",
    "\n",
    "ax[1].pie(before_pandemic_sizes, colors=colors, autopct='%1.1f%%', shadow=True, radius=1.2)\n",
    "ax[1].set_title(f'Before Pandemic ({sum(before_pandemic_sizes)})')\n",
    "\n",
    "ax[2].pie(during_pandemic_sizes, colors=colors, autopct='%1.1f%%', shadow=True, radius=1.2)\n",
    "ax[2].set_title(f'During Pandemic ({sum(during_pandemic_sizes)})')\n",
    "\n",
    "ax[1].legend(labels=labels, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before and After Pandemic - Manually Separated JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before_pandemic_emotions_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\twitter_sentiment_analysis\\POI_Followers_13-06-20\\all_top40_percent_tweets\\all_tweet_emotions_before_pandemic.json'\n",
    "during_pandemic_emotions_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\twitter_sentiment_analysis\\POI_Followers_13-06-20\\all_top40_percent_tweets\\all_tweet_emotions_during_pandemic.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ast import literal_eval as make_tuple\n",
    "\n",
    "with open(before_pandemic_emotions_path, 'r') as f:\n",
    "    before_pandemic_emotions = json.load(f)\n",
    "print(len(before_pandemic_emotions))\n",
    "    \n",
    "with open(during_pandemic_emotions_path, 'r') as f:\n",
    "    during_pandemic_emotions = json.load(f)\n",
    "print(len(during_pandemic_emotions))\n",
    "\n",
    "before_pandemic_tweet_emotions = {tweet_id : make_tuple(tup_str) for tweet_id, tup_str in before_pandemic_emotions.items()}\n",
    "during_pandemic_tweet_emotions = {tweet_id : make_tuple(tup_str) for tweet_id, tup_str in during_pandemic_emotions.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Emotion Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['Anger',\n",
    "          'Disgust',\n",
    "          'Fear',\n",
    "          'Joy',\n",
    "          'Sadness',\n",
    "          'Surprise']\n",
    "colors = ['red', \n",
    "          'brown', \n",
    "          'orange', \n",
    "          'limegreen', \n",
    "          'grey', \n",
    "          'deepskyblue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before_pandemic_aggregated_emotions = {label: 0 for label in labels}\n",
    "during_pandemic_aggregated_emotions = {label: 0 for label in labels}\n",
    "\n",
    "for _, emotions in before_pandemic_tweet_emotions.items():\n",
    "    for i, emotion_value in enumerate(emotions):\n",
    "        before_pandemic_aggregated_emotions[labels[i]] += emotion_value\n",
    "        \n",
    "for _, emotions in during_pandemic_tweet_emotions.items():\n",
    "    for i, emotion_value in enumerate(emotions):\n",
    "        during_pandemic_aggregated_emotions[labels[i]] += emotion_value\n",
    "\n",
    "for emotion in labels:\n",
    "    before_pandemic_aggregated_emotions[emotion] /= len(before_pandemic_tweet_emotions)\n",
    "    during_pandemic_aggregated_emotions[emotion] /= len(during_pandemic_tweet_emotions)\n",
    "\n",
    "print(before_pandemic_aggregated_emotions)\n",
    "print(during_pandemic_aggregated_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "mpl.rcParams['font.size'] = 15.0\n",
    "\n",
    "ax[0].pie(before_pandemic_aggregated_emotions.values(), colors=colors, autopct='%1.1f%%', radius=1.2)\n",
    "ax[0].set_title('Before Pandemic')\n",
    "\n",
    "ax[1].pie(during_pandemic_aggregated_emotions.values(), colors=colors, autopct='%1.1f%%', radius=1.2)\n",
    "ax[1].set_title('During Pandemic')\n",
    "\n",
    "plt.legend(labels, loc='upper center', bbox_to_anchor=(-0.1, -0.1), fancybox=True, shadow=True, ncol=len(labels))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Recognition Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RECOGNITION_THRESHOLD = 0.99\n",
    "\n",
    "def get_emotion_from_prob_list(prob_list):\n",
    "    if max(prob_list) < RECOGNITION_THRESHOLD:\n",
    "        return 'None'\n",
    "    return ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise'][prob_list.index(max(prob_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discrete_before_pandemic_tweet_emotions = {tweet_id : get_emotion_from_prob_list(prob_list) for tweet_id, prob_list in before_pandemic_tweet_emotions.items()}\n",
    "discrete_during_pandemic_tweet_emotions = {tweet_id : get_emotion_from_prob_list(prob_list) for tweet_id, prob_list in during_pandemic_tweet_emotions.items()}\n",
    "\n",
    "discrete_before_pandemic_tweet_emotions = {tweet_id : emotion for tweet_id, emotion in discrete_before_pandemic_tweet_emotions.items() if emotion != 'None'}\n",
    "discrete_during_pandemic_tweet_emotions = {tweet_id : emotion for tweet_id, emotion in discrete_during_pandemic_tweet_emotions.items() if emotion != 'None'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['Anger',\n",
    "          #'Disgust',\n",
    "          'Fear',\n",
    "          'Joy',\n",
    "          'Sadness',\n",
    "          'Surprise']\n",
    "colors = ['red', \n",
    "          #'brown', \n",
    "          'orange', \n",
    "          'limegreen', \n",
    "          'grey', \n",
    "          'deepskyblue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotions_only_before_pandemic = [emotion for _, emotion in discrete_before_pandemic_tweet_emotions.items()]\n",
    "emotions_only_during_pandemic = [emotion for _, emotion in discrete_during_pandemic_tweet_emotions.items()]\n",
    "\n",
    "all_tweets_sizes_before = [emotions_only_before_pandemic.count('Anger'), \n",
    "                           #emotions_only_before_pandemic.count('Disgust'), \n",
    "                           emotions_only_before_pandemic.count('Fear'), \n",
    "                           emotions_only_before_pandemic.count('Joy'), \n",
    "                           emotions_only_before_pandemic.count('Sadness'),\n",
    "                           emotions_only_before_pandemic.count('Surprise')]\n",
    "\n",
    "all_tweets_sizes_during = [emotions_only_during_pandemic.count('Anger'), \n",
    "                           #emotions_only_during_pandemic.count('Disgust'), \n",
    "                           emotions_only_during_pandemic.count('Fear'), \n",
    "                           emotions_only_during_pandemic.count('Joy'), \n",
    "                           emotions_only_during_pandemic.count('Sadness'), \n",
    "                           emotions_only_during_pandemic.count('Surprise')]\n",
    "\n",
    "print(f'{len(emotions_only_before_pandemic)} tweets total BEFORE PANDEMIC for threshold {RECOGNITION_THRESHOLD}')\n",
    "print(' '.join([f'{label}: {100.0 * emotions_only_before_pandemic.count(label) / len(emotions_only_before_pandemic):.2f}%' for label in labels]))\n",
    "print(f'{len(emotions_only_during_pandemic)} tweets total DURING PANDEMIC for threshold {RECOGNITION_THRESHOLD}')\n",
    "print(' '.join([f'{label}: {100.0 * emotions_only_during_pandemic.count(label) / len(emotions_only_during_pandemic):.2f}%' for label in labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "mpl.rcParams['font.size'] = 15.0\n",
    "\n",
    "ax[0].pie(all_tweets_sizes_before, colors=colors, autopct='%1.1f%%', radius=1.2)\n",
    "ax[0].set_title('Before Pandemic')\n",
    "print(f'Before the pandemic there were {sum(all_tweets_sizes_before)} tweets')\n",
    "\n",
    "ax[1].pie(all_tweets_sizes_during, colors=colors, autopct='%1.1f%%', radius=1.2)\n",
    "ax[1].set_title('During Pandemic')\n",
    "print(f'During the pandemic there were {sum(all_tweets_sizes_during)} tweets')\n",
    "\n",
    "plt.legend(labels, loc='upper center', bbox_to_anchor=(-0.1, -0.1), fancybox=True, shadow=True, ncol=len(labels))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Topic Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "database_path = r\"D:\\iliapl\\topic_modeling\\data\\databases\\bad_actors_Coronavirus_Project_POI_Followers_13-06-20.db\"\n",
    "model_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_25TOPICS'\n",
    "sentiment_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\twitter_sentiment_analysis\\POI_Followers_13-06-20\\all_top40_percent_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics_to_show = [0, 1, 2, 3, 4, 5, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['Anger',\n",
    "          'Disgust',\n",
    "          'Fear',\n",
    "          'Joy',\n",
    "          'Sadness',\n",
    "          'Surprise']\n",
    "colors = ['red',\n",
    "          'brown', \n",
    "          'orange', \n",
    "          'limegreen', \n",
    "          'grey', \n",
    "          'deepskyblue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('{}/tweet_topic_map.json'.format(model_path), 'r') as f:\n",
    "    tweet_topic_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval as make_tuple\n",
    "\n",
    "tweet_topic_map = {tweet_id: make_tuple(topic_prob)[0] for tweet_id, topic_prob in tweet_topic_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('{}/all_tweet_emotions_during_pandemic.json'.format(sentiment_path), 'r') as f:\n",
    "    tweet_emotions_raw = {tweet_id : make_tuple(emotion_tuple) for tweet_id, emotion_tuple in json.load(f).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Emotion Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic_aggregated_emotions = {topic: {label: 0 for label in labels} for topic in topics_to_show}\n",
    "topic_tweet_count = {topic: 0 for topic in topics_to_show}\n",
    "\n",
    "for tweet_id, topic_id in tweet_topic_map.items():\n",
    "    if topic_id not in topics_to_show or tweet_id not in tweet_emotions_raw:\n",
    "        continue\n",
    "        \n",
    "    emotions = tweet_emotions_raw[tweet_id]\n",
    "    for i, emotion_value in enumerate(emotions):\n",
    "        topic_aggregated_emotions[topic_id][labels[i]] += emotion_value\n",
    "    topic_tweet_count[topic_id] += 1\n",
    "    \n",
    "for topic in topics_to_show:\n",
    "    for label in labels:\n",
    "        topic_aggregated_emotions[topic][label] /= topic_tweet_count[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# multiple\n",
    "\n",
    "mpl.rcParams['font.size'] = 18.0\n",
    "\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(40, 20))\n",
    "\n",
    "\n",
    "for i, topic_id in enumerate(topics_to_show):\n",
    "    axes[int(i / ncols)][i % ncols].pie(topic_aggregated_emotions[topic_id].values(), colors=colors, autopct='%1.1f%%', textprops={'fontsize': 18}, shadow=False, radius=1.22)\n",
    "    axes[int(i / ncols)][i % ncols].set_title(f'Topic {topic_id} Emotions (# tweets: {topic_tweet_count[topic_id]})')\n",
    "\n",
    "plt.legend(labels, loc='upper center', bbox_to_anchor=(-1.25, -0.1), fancybox=True, shadow=True, ncol=len(labels))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Recognition Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RECOGNITION_THRESHOLD = 0.9\n",
    "\n",
    "def get_emotion_from_prob_list(prob_list):\n",
    "    if max(prob_list) < RECOGNITION_THRESHOLD:\n",
    "        return 'None'\n",
    "    return ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise'][prob_list.index(max(prob_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_emotions = {tweet_id : get_emotion_from_prob_list(emotion_tup) for tweet_id, emotion_tup in tweet_emotions_raw.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_topic_emotions = {i : {'Anger': 0, 'Disgust': 0, 'Fear': 0, 'Joy': 0, 'Sadness': 0, 'Surprise': 0} for i in range(NUM_TOPICS)}\n",
    "\n",
    "for tweet_id, topic_id in tweet_topic_map.items():\n",
    "    if tweet_id in tweet_emotions:\n",
    "        if tweet_emotions[tweet_id] != 'None':\n",
    "            tweet_topic_emotions[topic_id][tweet_emotions[tweet_id]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_topic_count = {i : sum(tweet_topic_emotions[i].values()) for i in range(NUM_TOPICS)}\n",
    "print(tweet_topic_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['Anger',\n",
    "          #'Disgust',\n",
    "          'Fear',\n",
    "          'Joy',\n",
    "          'Sadness',\n",
    "          'Surprise']\n",
    "colors = ['red', \n",
    "          #'brown', \n",
    "          'orange', \n",
    "          'limegreen', \n",
    "          'grey', \n",
    "          'deepskyblue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_ids = list(range(25))\n",
    "\n",
    "emotion_counts = {topic_id : [tweet_topic_emotions[topic_id]['Anger'],\n",
    "                              #tweet_topic_emotions[topic_id]['Disgust'], \n",
    "                              tweet_topic_emotions[topic_id]['Fear'],\n",
    "                              tweet_topic_emotions[topic_id]['Joy'], \n",
    "                            tweet_topic_emotions[topic_id]['Sadness'],\n",
    "                              tweet_topic_emotions[topic_id]['Surprise']] for topic_id in topic_ids}\n",
    "\n",
    "for topic_id in topic_ids:\n",
    "    print(f'TOPIC {topic_id}')\n",
    "    print(f'{tweet_topic_count[topic_id]} tweets total BEFORE PANDEMIC for threshold {RECOGNITION_THRESHOLD}')\n",
    "    print(' '.join([f'{label}: {100.0 * tweet_topic_emotions[topic_id][label] / tweet_topic_count[topic_id]:.2f}%' for label in labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# multiple\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(40, 20))\n",
    "\n",
    "\n",
    "for topic_id in topic_ids:\n",
    "    axes[int(topic_id / 5)][topic_id % 5].pie(emotion_counts[topic_id], colors=colors, autopct='%1.1f%%', textprops={'fontsize': 14}, shadow=True, radius=1.2)\n",
    "    axes[int(topic_id / 5)][topic_id % 5].set_title(f'Topic {topic_id} Emotions (thres.: {RECOGNITION_THRESHOLD}, # tweets: {tweet_topic_count[topic_id]})')\n",
    "\n",
    "plt.legend(labels=labels, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# one topic per iteration\n",
    "\n",
    "for topic_id in topic_ids:\n",
    "    f, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    mpl.rcParams['font.size'] = 15.0\n",
    "\n",
    "    plt.pie(emotion_counts[topic_id], colors=colors, autopct='%1.1f%%', textprops={'fontsize': 14}, shadow=False, radius=1.2)\n",
    "    plt.title(f'Topic {topic_id} Emotions (thres.: {RECOGNITION_THRESHOLD}, # tweets: {tweet_topic_count[topic_id]})')\n",
    "    plt.legend(labels=labels, loc='upper left')\n",
    "    \n",
    "    plt.savefig(r'C:\\Users\\iliapl\\Documents\\CoronaVirusProject\\data\\output_data\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_25TOPICS\\emotions_topic{}_thresh{}.png'.format(topic_id, RECOGNITION_THRESHOLD))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
