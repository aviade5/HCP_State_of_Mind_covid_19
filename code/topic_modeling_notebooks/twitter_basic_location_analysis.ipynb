{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = r\"C:\\Users\\User\\Documents\\University\\Research\\FakeNews\\CoronaVirusProject\\data\\twitter_posts_30-12-2019_22-03-2020.db\"\n",
    "output_path = r'C:\\Users\\User\\Documents\\University\\Research\\FakeNews\\CoronaVirusProject\\data\\twitter_location_analysis\\twitter_posts_30-12-2019_22-03-2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import time\n",
    "\n",
    "T = time.time()\n",
    "\n",
    "conn = sql.connect(database_path)\n",
    "cur = conn.cursor()\n",
    "query = \"SELECT post_id, author FROM posts WHERE date > date('2019-12-31')\"\n",
    "tweet_authors = cur.execute(query).fetchall()\n",
    "\n",
    "T = time.time() - T\n",
    "print('Tweet IDs retrieved in {} seconds'.format(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Got {} tweets with their authors'.format(len(tweet_authors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [tweet[1] for tweet in tweet_authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_parsed_locations = {}\n",
    "for author in set(authors):\n",
    "    query = \"SELECT location FROM authors WHERE name='{}'\".format(author)\n",
    "    location = cur.execute(query).fetchall()\n",
    "    author_parsed_locations[author] = location\n",
    "    \n",
    "fixed_author_parsed_locations = {}\n",
    "for author, location in author_parsed_locations.items():\n",
    "    if location:\n",
    "        if location[0][0]:\n",
    "            fixed_author_parsed_locations[author] = location[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_tweet_authors = [(tweet_id, author) for (tweet_id, author) in tweet_authors if author in fixed_author_parsed_locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_locations = [(tweet_id, fixed_author_parsed_locations[author]) for (tweet_id, author) in fixed_tweet_authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "country_name_dict = {}\n",
    "\n",
    "if os.path.isfile('{}/country_name_dict.json'.format(output_path)):\n",
    "    with open('{}/country_name_dict.json'.format(output_path), 'r') as file_handle:\n",
    "        country_name_dict = json.load(file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name_dict = {}\n",
    "\n",
    "if os.path.isfile('{}/state_name_dict.json'.format(output_path)):\n",
    "    with open('{}/state_name_dict.json'.format(output_path), 'r') as file_handle:\n",
    "        state_name_dict = json.load(file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_countries = {}\n",
    "if os.path.isfile('{}/tweet_countries.json'.format(output_path)):\n",
    "    with open('{}/tweet_countries.json'.format(output_path), 'r') as file_handle:\n",
    "        tweet_countries = json.load(file_handle)\n",
    "\n",
    "tweet_states = {}\n",
    "if os.path.isfile('{}/tweet_states.json'.format(output_path)):\n",
    "    with open('{}/tweet_states.json'.format(output_path), 'r') as file_handle:\n",
    "        tweet_states = json.load(file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_country_names = set()\n",
    "if os.path.isfile('{}/bad_country_names.json'.format(output_path)):\n",
    "    with open('{}/bad_country_names.json'.format(output_path), 'r') as file_handle:\n",
    "        bad_country_names = set(json.load(file_handle))\n",
    "\n",
    "bad_state_names = set()\n",
    "if os.path.isfile('{}/bad_state_names.json'.format(output_path)):\n",
    "    with open('{}/bad_state_names.json'.format(output_path), 'r') as file_handle:\n",
    "        bad_state_names = set(json.load(file_handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_exceptions = {}\n",
    "if os.path.isfile('{}/state_exceptions.json'.format(output_path)):\n",
    "    with open('{}/state_exceptions.json'.format(output_path), 'r') as file_handle:\n",
    "        state_exceptions = json.load(file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_state_exception(parsed_location, state):\n",
    "    state_exceptions[parsed_location] = state\n",
    "    with open('{}/state_exceptions.json'.format(output_path), 'w') as file_handle:\n",
    "        json.dump(state_exceptions, file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Bing(api_key=\"AgSzclXa0ydRjeopKMp_qtSEob_A6_LHG8-bq2RMnGIadjGRPRUKANZiKlKdLw4I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Bing\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderQueryError, GeocoderQuotaExceeded, GeocoderServiceError\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "def get_country_name_by_bing_api(parsed_location, country_type):\n",
    "    if country_type != 'country' and country_type != 'state':\n",
    "        print('Country type must be either country state')\n",
    "        return \"\", True\n",
    "    if not parsed_location.strip():\n",
    "        return \"\", True\n",
    "    if parsed_location in bad_country_names:\n",
    "        return \"\", True    \n",
    "    if country_type == 'state' and parsed_location in bad_state_names:\n",
    "        return \"\", True\n",
    "    if country_type == 'state':\n",
    "        for state_exception in state_exceptions:\n",
    "            if state_exception in parsed_location.lower():\n",
    "                return state_exceptions[state_exception], True\n",
    "    if country_type == 'country' and parsed_location in country_name_dict:\n",
    "        return country_name_dict[parsed_location], True\n",
    "    if country_type == 'state' and parsed_location in state_name_dict:\n",
    "        return state_name_dict[parsed_location], True\n",
    "    \n",
    "    try:\n",
    "        location = geolocator.geocode(parsed_location)\n",
    "        if location is None: # fail\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        if 'address' not in location.raw:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        if 'countryRegion' not in location.raw['address']:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        country_name = location.raw['address']['countryRegion']\n",
    "        country_name_dict[parsed_location] = country_name\n",
    "        if country_name == 'United States':\n",
    "            if 'adminDistrict' not in location.raw['address']:\n",
    "                bad_state_names.add(parsed_location)\n",
    "                if country_type == 'state':\n",
    "                    return \"\", False\n",
    "            else:\n",
    "                state = location.raw['address']['adminDistrict']\n",
    "                state_name_dict[parsed_location] = state\n",
    "                if country_type == 'state':\n",
    "                    return state, False\n",
    "        else:\n",
    "            if country_type == 'state':\n",
    "                return \"\", False\n",
    "        if country_type == 'country':\n",
    "            return country_name, False\n",
    "        else:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "\n",
    "    except GeocoderTimedOut as e:\n",
    "        print(e)\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            location = geolocator.geocode(parsed_location)\n",
    "        except GeocoderTimedOut as e2:\n",
    "            success = False\n",
    "            while not success:\n",
    "                time.sleep(5)\n",
    "                try:\n",
    "                    location = geolocator.geocode(parsed_location)\n",
    "                    success = True\n",
    "                except GeocoderTimedOut as e3:\n",
    "                    pass\n",
    "        if location is None: # fail\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        if 'address' not in location.raw:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        if 'countryRegion' not in location.raw['address']:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        country_name = location.raw['address']['countryRegion']\n",
    "        country_name_dict[parsed_location] = country_name\n",
    "        if country_name == 'United States':\n",
    "            if 'adminDistrict' not in location.raw['address']:\n",
    "                bad_state_names.add(parsed_location)\n",
    "                print('ATTENTION: {} added to bad states set'.format(parsed_location))\n",
    "                if country_type == 'state':\n",
    "                    return \"\", False\n",
    "            else:\n",
    "                state = location.raw['address']['adminDistrict']\n",
    "                state_name_dict[parsed_location] = state\n",
    "                if country_type == 'state':\n",
    "                    return state, False\n",
    "        else:\n",
    "            if country_type == 'state':\n",
    "                return \"\", False\n",
    "        if country_type == 'country':\n",
    "            return country_name, False\n",
    "        else:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "    except GeocoderQueryError as e:\n",
    "        bad_country_names.add(parsed_location)\n",
    "        print('Query error! query: {}'.format(parsed_location))\n",
    "        return \"Bad_Request\", False\n",
    "\n",
    "    except GeocoderQuotaExceeded as e:\n",
    "        print('Quota exceeded!')\n",
    "        time.sleep(1.5)\n",
    "        return \"Bad_Request\", False\n",
    "    \n",
    "    except GeocoderServiceError as e:\n",
    "        print('Service error!')\n",
    "        time.sleep(1)\n",
    "        return \"Bad_Request\", False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_requests = 0\n",
    "num_requests_total = 0\n",
    "start_time = time.time()\n",
    "for i, (tweet, location) in enumerate(tweet_locations, 1):\n",
    "    if tweet in tweet_countries:\n",
    "        continue\n",
    "    country_name, is_cached = get_country_name_by_bing_api(location, 'country')\n",
    "    if not is_cached:\n",
    "        num_requests_total += 1\n",
    "        if num_requests_total % 500 == 0:\n",
    "            with open('{}/country_name_dict.json'.format(output_path), 'w') as handle:\n",
    "                json.dump(country_name_dict, handle)\n",
    "            with open('{}/state_name_dict.json'.format(output_path), 'w') as handle:\n",
    "                json.dump(state_name_dict, handle)\n",
    "            with open('{}/bad_country_names.json'.format(output_path), 'w') as handle:\n",
    "                json.dump(list(bad_country_names), handle)\n",
    "            with open('{}/bad_state_names.json'.format(output_path), 'w') as handle:\n",
    "                json.dump(list(bad_state_names), handle)\n",
    "\n",
    "            print(\"Dictionary was saved! \")\n",
    "\n",
    "    if country_name == 'Bad_Request':\n",
    "        bad_requests += 1\n",
    "    else:\n",
    "        if country_name:\n",
    "            tweet_countries[tweet] = country_name\n",
    "    if i % 10000 == 0:\n",
    "        print('Finished {} tweets. So far {} requests total. {} seconds total.'.format(i, num_requests_total, time.time() - start_time))\n",
    "\n",
    "print('Finished {} tweets. {} bad requests.'.format(len(tweet_locations), bad_requests))\n",
    "\n",
    "with open('{}/country_name_dict.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(country_name_dict, handle)\n",
    "with open('{}/state_name_dict.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(state_name_dict, handle)\n",
    "with open('{}/bad_country_names.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(list(bad_country_names), handle)\n",
    "with open('{}/bad_state_names.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(list(bad_state_names), handle)\n",
    "    \n",
    "with open('{}/tweet_countries.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(tweet_countries, handle)\n",
    "    \n",
    "print(\"Dictionary was saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "\n",
    "geolocator = Nominatim(user_agent='-')\n",
    "def geolocate(country):\n",
    "    try:\n",
    "        loc = geolocator.geocode(country)\n",
    "        return (loc.latitude, loc.longitude)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('{}/tweet_countries.json'.format(output_path), 'w') as file_handle:\n",
    "    json.dump(tweet_countries, file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = [country for (tweet_id, country) in tweet_countries.items()]\n",
    "country_names = sorted(list(set([country for (_, country) in tweet_countries.items()])))\n",
    "name_coordinate_map = {}\n",
    "for country in country_names:\n",
    "    latlon = geolocate(country)\n",
    "    if latlon != latlon: # if latlon is nan\n",
    "        continue\n",
    "    name_coordinate_map[country] = latlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2\n",
    "\n",
    "def get_continent(col):\n",
    "    try:\n",
    "        cn_a2_code = country_name_to_country_alpha2(col)\n",
    "    except:\n",
    "        cn_a2_code = 'Unknown'\n",
    "    try:\n",
    "        cn_continent = country_alpha2_to_continent_code(cn_a2_code)\n",
    "    except:\n",
    "        cn_continent = 'Unknown'\n",
    "    return (cn_a2_code, cn_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_alpha3_code(alpha2_code):\n",
    "    with open('{}/country_alpha_codes.json'.format(output_path), 'r') as file_handle:\n",
    "        country_codes_list = json.load(file_handle)    \n",
    "    for country in country_codes_list:\n",
    "        if country['alpha2'].lower() == alpha2_code.lower():\n",
    "            return country['alpha3'].upper()\n",
    "    return 'INVALID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "country_tweet_count_tup_list = [(country, country_list.count(country)) for country in name_coordinate_map.keys()]\n",
    "df = pd.DataFrame({'country_name' : [country for (country, c_count) in country_tweet_count_tup_list],\n",
    "                  'tweet_count' : [c_count for (country, c_count) in country_tweet_count_tup_list],\n",
    "                  'alpha-2-code' : [get_continent(country)[0] for (country, _) in country_tweet_count_tup_list],\n",
    "                   'alpha-3-code' : [get_alpha3_code(get_continent(country)[0]) for (country, _) in country_tweet_count_tup_list],\n",
    "                  'continent_code': [get_continent(country)[1] for (country, _) in country_tweet_count_tup_list]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'] = [name_coordinate_map[country][0] for (country, _) in country_tweet_count_tup_list]\n",
    "df['longitude'] = [name_coordinate_map[country][1] for (country, _) in country_tweet_count_tup_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "world_map = folium.Map(titles=\"cartodbpositron\")\n",
    "folium.Choropleth('{}/world_countries.json'.format(output_path), fill_color='Reds',\n",
    "                    data=df, columns=['alpha-3-code', 'tweet_count'], key_on='feature.id', nan_fill_color='white',\n",
    "                     legend_name='Tweet count', fill_opacity=0.7, line_opacity=0.2).add_to(world_map)\n",
    "marker_cluster = MarkerCluster().add_to(world_map)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    lat = df.iloc[i]['latitude']\n",
    "    long = df.iloc[i]['longitude']\n",
    "    popup_text = 'Country: {}<br> #Tweets: {}'.format(df.iloc[i]['country_name'], df.iloc[i]['tweet_count'])\n",
    "    folium.CircleMarker(location = [lat, long], radius=5, popup=popup_text, fill=True).add_to(marker_cluster)\n",
    "    \n",
    "world_map.save('{}/world_map.html'.format(output_path))\n",
    "world_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['country_name'] == 'United States'].index)\n",
    "\n",
    "world_map = folium.Map(titles=\"cartodbpositron\")\n",
    "folium.Choropleth('{}/world_countries.json'.format(output_path), fill_color='Reds',\n",
    "                    data=df, columns=['alpha-3-code', 'tweet_count'], key_on='feature.id', nan_fill_color='white',\n",
    "                     legend_name='Tweet count', fill_opacity=0.7, line_opacity=0.2).add_to(world_map)\n",
    "marker_cluster = MarkerCluster().add_to(world_map)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    lat = df.iloc[i]['latitude']\n",
    "    long = df.iloc[i]['longitude']\n",
    "    popup_text = 'Country: {}<br> #Tweets: {}'.format(df.iloc[i]['country_name'], df.iloc[i]['tweet_count'])\n",
    "    folium.CircleMarker(location = [lat, long], radius=5, popup=popup_text, fill=True).add_to(marker_cluster)\n",
    "    \n",
    "world_map.save('{}/world_map_no_us.html'.format(output_path))\n",
    "world_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topn_countries(df, topn):\n",
    "    country_tweet_count_list = [(df.iloc[i]['country_name'], count) for (i, count) in enumerate(list(df['tweet_count']))]\n",
    "    sorted_list = sorted(country_tweet_count_list, key=lambda tup: tup[1], reverse=True)\n",
    "    return sorted_list[:topn]\n",
    "\n",
    "get_topn_countries(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_count_dict_with_us = {country_name : country_list.count(country_name) for country_name in set(country_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_country_count_dict_with_us = sorted(list(country_count_dict_with_us.items()), reverse=True, key=lambda tup: tup[1])[:10]\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "ax.set_ylabel('Number of tweets')\n",
    "ax.set_title('Tweets per country')\n",
    "plt.bar([country for (country, _) in top10_country_count_dict_with_us], [count for (_, count) in top10_country_count_dict_with_us])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_locations_dict = {tweet_id : location for (tweet_id, location) in tweet_locations}\n",
    "us_tweet_locations = {tweet_id : tweet_locations_dict[tweet_id] for (tweet_id, tweet_country) in tweet_countries.items() if tweet_country == 'United States'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_requests = 0\n",
    "num_requests_total = 0\n",
    "start_time = time.time()\n",
    "for i, (tweet, location) in enumerate(us_tweet_locations.items(), 1):\n",
    "    if tweet in tweet_states:\n",
    "        continue\n",
    "\n",
    "    state_name, is_cached = get_country_name_by_bing_api(location, 'state')\n",
    "    if not is_cached:\n",
    "        num_requests_total += 1\n",
    "    if state_name == 'Bad_Request':\n",
    "        bad_requests += 1\n",
    "    else:\n",
    "        if state_name:\n",
    "            tweet_states[tweet] = state_name\n",
    "    if i % 10000 == 0:\n",
    "        print('Finished {} tweets. So far {} requests total. {} seconds total.'.format(i, num_requests_total, time.time() - start_time))\n",
    "print('Finished {} tweets. {} bad requests.'.format(len(tweet_states), bad_requests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix arbitrary bing errors\n",
    "for tweet in tweet_states:\n",
    "    if tweet_states[tweet] == 'Nevada':\n",
    "        tweet_states[tweet] = 'NV'\n",
    "    if tweet_states[tweet] == 'New York':\n",
    "        tweet_states[tweet] = 'NY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/tweet_states.json'.format(output_path), 'w') as file_handle:\n",
    "    json.dump(tweet_states, file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = [state for (_, state) in tweet_states.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_counts = {}\n",
    "for state in set(state_list):\n",
    "    state_counts[state] = state_list.count(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_counts_list = list(state_counts.items())\n",
    "states_df = pd.DataFrame({'state_code': [state for (state, _) in state_counts_list], 'tweet_count': [count for (_, count) in state_counts_list]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent='-')\n",
    "\n",
    "with open('{}/state_code_name.json'.format(output_path)) as file_handle:\n",
    "    state_code_names = json.load(file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_coordinates = []\n",
    "\n",
    "for state_code in [state_code for (state_code, _) in state_counts_list]:\n",
    "    state_name = state_code_names[state_code]\n",
    "    if state_name == 'Washington':\n",
    "        state_name = 'Washington state'\n",
    "    try:\n",
    "        location = geolocator.geocode(state_name)\n",
    "        state_coordinates.append((location.latitude, location.longitude))\n",
    "    except:\n",
    "        print('COULD NOT GEOCODE: {}'.format(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df['latitude'] = [coordinates[0] for coordinates in state_coordinates]\n",
    "states_df['longitude'] = [coordinates[1] for coordinates in state_coordinates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "state_map = folium.Map(titles=\"cartodbpositron\")\n",
    "folium.Choropleth('{}/us_states.json'.format(output_path), fill_color='Reds',\n",
    "                    data=states_df, columns=['state_code', 'tweet_count'], key_on='feature.id', nan_fill_color='white',\n",
    "                     legend_name='Tweet count', fill_opacity=0.7, line_opacity=0.2).add_to(state_map)\n",
    "marker_cluster = MarkerCluster().add_to(state_map)\n",
    "\n",
    "for i in range(len(states_df)):\n",
    "    lat = states_df.iloc[i]['latitude']\n",
    "    long = states_df.iloc[i]['longitude']\n",
    "    popup_text = 'State: {}<br> #Tweets: {}'.format(state_code_names[states_df.iloc[i]['state_code']], states_df.iloc[i]['tweet_count'])\n",
    "    folium.CircleMarker(location = [lat, long], radius=5, popup=popup_text, fill=True).add_to(marker_cluster)\n",
    "    \n",
    "state_map.save('{}/state_map.html'.format(output_path))\n",
    "state_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topn_states(df, topn):\n",
    "    state_tweet_count_list = [(state_code_names[df.iloc[i]['state_code']], count) for (i, count) in enumerate(list(df['tweet_count']))]\n",
    "    sorted_list = sorted(state_tweet_count_list, key=lambda tup: tup[1], reverse=True)\n",
    "    return sorted_list[:topn]\n",
    "\n",
    "get_topn_states(states_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "state_counts = get_topn_states(states_df, 15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "ax.set_ylabel('Number of tweets')\n",
    "ax.set_title('Tweets per state')\n",
    "plt.bar([state for (state, _) in state_counts], [count for (_, count) in state_counts])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporary\n",
    "import json\n",
    "\n",
    "with open(r'D:\\iliapl\\topic_modeling\\data\\output_data\\POI_Followers_13-06-20_PERSON_ONLY_V10_TOP40PERCENT_25TOPICS\\tweet_author_map.json', 'r') as f:\n",
    "    tweet_author_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\iliapl\\topic_modeling\\data\\output_data\\twitter_location_analysis\\POI_Followers_13-06-20\\tweet_countries.json', 'r') as f:\n",
    "        tweet_countries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for tweet in tweet_countries:\n",
    "    if tweet in tweet_author_map and tweet_countries[tweet] == 'New Zealand':\n",
    "        sum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_countries = {}\n",
    "for tweet in tweet_author_map:\n",
    "    author = tweet_author_map[tweet]\n",
    "    if author not in author_countries and tweet in tweet_countries:\n",
    "        author_countries[author] = tweet_countries[tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_country_count = {}\n",
    "for author in author_countries:\n",
    "    country = author_countries[author]\n",
    "    author_country_count[country] = author_country_count.get(country, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "country_count_tuples = sorted(list(author_country_count.items()), reverse=True, key=lambda tup: tup[1])[20:30]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar([tup[0] for tup in country_count_tuples], [tup[1] for tup in country_count_tuples], align='center')\n",
    "plt.title('Number of Authors per Country')\n",
    "#plt.xticks(range(len(author_country_count)), country_count_tuples)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_country_count['New Zealand']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
