{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = r\"D:\\iliapl\\topic_modeling\\data\\databases\\53k_individual_hcps_70_percent_confidence_tweets.db\"\n",
    "output_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\twitter_location_analysis\\author_location_data_53k_authors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "\n",
    "con = sql.connect(database_path)\n",
    "authors_df = pd.read_sql('SELECT * FROM authors', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = authors_df[['name', 'author_osn_id', 'location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Bing\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderQueryError, GeocoderQuotaExceeded, GeocoderServiceError\n",
    "\n",
    "geolocator = Bing(api_key=\"AgSzclXa0ydRjeopKMp_qtSEob_A6_LHG8-bq2RMnGIadjGRPRUKANZiKlKdLw4I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premade_parsed_location_dict_path = r'D:\\iliapl\\topic_modeling\\data\\output_data\\twitter_location_analysis\\POI_Followers_13-06-20\\country_name_dict.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bad_country_names = set()\n",
    "bad_state_names = set()\n",
    "\n",
    "state_name_dict = {}\n",
    "\n",
    "with open(premade_parsed_location_dict_path, 'r') as f:\n",
    "    parsed_location_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Bing\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderQueryError, GeocoderQuotaExceeded, GeocoderServiceError\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "def get_country_name_by_bing_api(parsed_location, country_type):\n",
    "    if country_type != 'country' and country_type != 'state':\n",
    "        print('Country type must be either country state')\n",
    "        return \"\", True\n",
    "    if not parsed_location.strip():\n",
    "        return \"\", True\n",
    "    if parsed_location in bad_country_names:\n",
    "        return \"\", True    \n",
    "    if country_type == 'state' and parsed_location in bad_state_names:\n",
    "        return \"\", True\n",
    "    if country_type == 'state':\n",
    "        for state_exception in state_exceptions:\n",
    "            if state_exception in parsed_location.lower():\n",
    "                return state_exceptions[state_exception], True\n",
    "    if country_type == 'country' and parsed_location in parsed_location_dict:\n",
    "        return parsed_location_dict[parsed_location], True\n",
    "    if country_type == 'state' and parsed_location in state_name_dict:\n",
    "        return state_name_dict[parsed_location], True\n",
    "    \n",
    "    try:\n",
    "        location = geolocator.geocode(parsed_location)\n",
    "        if location is None: # fail\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        if 'address' not in location.raw:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        if 'countryRegion' not in location.raw['address']:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        country_name = location.raw['address']['countryRegion']\n",
    "        parsed_location_dict[parsed_location] = country_name\n",
    "        if country_name == 'United States':\n",
    "            if 'adminDistrict' not in location.raw['address']:\n",
    "                bad_state_names.add(parsed_location)\n",
    "                if country_type == 'state':\n",
    "                    return \"\", False\n",
    "            else:\n",
    "                state = location.raw['address']['adminDistrict']\n",
    "                state_name_dict[parsed_location] = state\n",
    "                if country_type == 'state':\n",
    "                    return state, False\n",
    "        else:\n",
    "            if country_type == 'state':\n",
    "                return \"\", False\n",
    "        if country_type == 'country':\n",
    "            return country_name, False\n",
    "        else:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "\n",
    "    except GeocoderTimedOut as e:\n",
    "        print(e)\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            location = geolocator.geocode(parsed_location)\n",
    "        except GeocoderTimedOut as e2:\n",
    "            success = False\n",
    "            while not success:\n",
    "                time.sleep(5)\n",
    "                try:\n",
    "                    location = geolocator.geocode(parsed_location)\n",
    "                    success = True\n",
    "                except GeocoderTimedOut as e3:\n",
    "                    pass\n",
    "        if location is None: # fail\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        if 'address' not in location.raw:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        if 'countryRegion' not in location.raw['address']:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "        country_name = location.raw['address']['countryRegion']\n",
    "        parsed_location_dict[parsed_location] = country_name\n",
    "        if country_name == 'United States':\n",
    "            if 'adminDistrict' not in location.raw['address']:\n",
    "                bad_state_names.add(parsed_location)\n",
    "                print('ATTENTION: {} added to bad states set'.format(parsed_location))\n",
    "                if country_type == 'state':\n",
    "                    return \"\", False\n",
    "            else:\n",
    "                state = location.raw['address']['adminDistrict']\n",
    "                state_name_dict[parsed_location] = state\n",
    "                if country_type == 'state':\n",
    "                    return state, False\n",
    "        else:\n",
    "            if country_type == 'state':\n",
    "                return \"\", False\n",
    "        if country_type == 'country':\n",
    "            return country_name, False\n",
    "        else:\n",
    "            bad_country_names.add(parsed_location)\n",
    "            return \"\", False\n",
    "    except GeocoderQueryError as e:\n",
    "        bad_country_names.add(parsed_location)\n",
    "        print('Query error! query: {}'.format(parsed_location))\n",
    "        return \"Bad_Request\", False\n",
    "\n",
    "    except GeocoderQuotaExceeded as e:\n",
    "        print('Quota exceeded!')\n",
    "        time.sleep(1.5)\n",
    "        return \"Bad_Request\", False\n",
    "    \n",
    "    except GeocoderServiceError as e:\n",
    "        print('Service error!')\n",
    "        time.sleep(1)\n",
    "        return \"Bad_Request\", False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_author_initial_location_dict = {}\n",
    "\n",
    "for entry in authors_df.itertuples():\n",
    "    twitter_author_initial_location_dict[(entry.name, str(entry.author_osn_id))] = entry.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_country_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "bad_requests = 0\n",
    "num_requests_total = 0\n",
    "start_time = time.time()\n",
    "for i, (author_tup, location) in enumerate(twitter_author_initial_location_dict.items(), 1):\n",
    "    \n",
    "    author_osn_id = author_tup[1]\n",
    "    \n",
    "    country_name, is_cached = get_country_name_by_bing_api(location, 'country')\n",
    "    if not is_cached:\n",
    "        num_requests_total += 1\n",
    "        if num_requests_total % 500 == 0:\n",
    "            with open('{}/parsed_location_dict.json'.format(output_path), 'w') as handle:\n",
    "                json.dump(parsed_location_dict, handle)\n",
    "            #with open('{}/state_name_dict.json'.format(output_path), 'w') as handle:\n",
    "            #    json.dump(state_name_dict, handle)\n",
    "            with open('{}/bad_country_names.json'.format(output_path), 'w') as handle:\n",
    "                json.dump(list(bad_country_names), handle)\n",
    "            with open('{}/bad_state_names.json'.format(output_path), 'w') as handle:\n",
    "                json.dump(list(bad_state_names), handle)\n",
    "            with open('{}/author_country_dict.json'.format(output_path), 'w') as handle:\n",
    "                json.dump(author_country_dict, handle)\n",
    "\n",
    "            print(\"Dictionary was saved! \")\n",
    "\n",
    "    if country_name == 'Bad_Request':\n",
    "        bad_requests += 1\n",
    "    else:\n",
    "        if country_name:\n",
    "            author_country_dict[author_osn_id] = country_name\n",
    "    if i % 10000 == 0:\n",
    "        print('Finished {} authors. So far {} requests total. {} seconds total.'.format(i, num_requests_total, time.time() - start_time))\n",
    "        \n",
    "print('Finished {} authors. {} bad requests.'.format(len(author_country_dict), bad_requests))\n",
    "\n",
    "with open('{}/parsed_location_dict.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(parsed_location_dict, handle)\n",
    "with open('{}/state_name_dict.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(state_name_dict, handle)\n",
    "with open('{}/bad_country_names.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(list(bad_country_names), handle)\n",
    "with open('{}/bad_state_names.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(list(bad_state_names), handle)\n",
    "    \n",
    "with open('{}/author_country_dict.json'.format(output_path), 'w') as handle:\n",
    "    json.dump(author_country_dict, handle)\n",
    "\n",
    "print(\"Dictionary was saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_country_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
